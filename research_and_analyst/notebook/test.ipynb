{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c0a2199",
   "metadata": {},
   "source": [
    "#### Project 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9adff13d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "notebook ok\n"
     ]
    }
   ],
   "source": [
    "# uv export --no-hashes > requirements.txt\n",
    "print(\"notebook ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5b6cbeb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from research_and_analyst.utils.model_loader import ModelLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d1cdccde",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\"timestamp\": \"2025-10-13T13:08:43.610944Z\", \"level\": \"info\", \"event\": \"GOOGLE_API_KEY loaded from environment\"}\n",
      "{\"timestamp\": \"2025-10-13T13:08:43.617896Z\", \"level\": \"info\", \"event\": \"GROQ_API_KEY loaded from environment\"}\n",
      "{\"timestamp\": \"2025-10-13T13:08:43.623050Z\", \"level\": \"warning\", \"event\": \"ASTRA_DB_API_ENDPOINT is missing from environment\"}\n",
      "{\"timestamp\": \"2025-10-13T13:08:43.629218Z\", \"level\": \"warning\", \"event\": \"ASTRA_DB_APPLICATION_TOKEN is missing from environment\"}\n",
      "{\"timestamp\": \"2025-10-13T13:08:43.634987Z\", \"level\": \"warning\", \"event\": \"ASTRA_DB_KEYSPACE is missing from environment\"}\n",
      "{\"config_keys\": [\"astra_db\", \"embedding_model\", \"retriever\", \"llm\"], \"timestamp\": \"2025-10-13T13:08:43.659923Z\", \"level\": \"info\", \"event\": \"YAML config loaded\"}\n"
     ]
    }
   ],
   "source": [
    "model_loader = ModelLoader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1babd0c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\"provider\": \"groq\", \"model\": \"llama-3.3-70b-versatile\", \"timestamp\": \"2025-10-13T13:09:27.128837Z\", \"level\": \"info\", \"event\": \"Loading LLM\"}\n"
     ]
    }
   ],
   "source": [
    "llm = model_loader.load_llm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35ac88cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello. I'm just a language model, so I don't have feelings or emotions like humans do, but I'm functioning properly and ready to assist you with any questions or tasks you may have. How can I help you today?\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 48, 'prompt_tokens': 41, 'total_tokens': 89, 'completion_time': 0.097114962, 'prompt_time': 0.00213851, 'queue_time': 0.09321595, 'total_time': 0.099253472}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_9e1e8f8435', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--a9601c56-9559-4bea-8e6a-639b82f9d6c4-0', usage_metadata={'input_tokens': 41, 'output_tokens': 48, 'total_tokens': 89})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"Hello, how are you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c4baff5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from typing_extensions import TypedDict\n",
    "from pydantic import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81001982",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ff0a9f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def human_feedback(state):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        state (_type_): _description_\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "71538cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_analyst(state):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        state (_type_): _description_\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "85e9d970",
   "metadata": {},
   "outputs": [],
   "source": [
    "def should_continue(state):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        state (_type_): _description_\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a51231d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "from langgraph.checkpoint.memory import MemorySaver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "edd89758",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Analyst(BaseModel):\n",
    "    \"\"\"_summary_\n",
    "    \"\"\"\n",
    "    name: str = Field(..., description=\"Name of the analyst\")\n",
    "    role: str = Field(..., description=\"Role of the analyst in the context of the topic\")\n",
    "    affiliation: str = Field(..., description=\"Primary affiliation of the analyst\")\n",
    "    description: str = Field(..., description=\"Description of the analyst focus, concerns, and motives\")\n",
    "\n",
    "    @property\n",
    "    def persona(self) -> str:\n",
    "        return f\"Name: {self.name}\\nRole: {self.role}\\nAffiliation: {self.affiliation}\\nDescription: {self.description}\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "13d8e5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perspective(BaseModel):\n",
    "    analysts: List[Analyst] = Field(..., description=\"Comprehensive list of analysts with their roles and affiliations.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "823df3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyst = Analyst(\n",
    "    name=\"klangat\",\n",
    "    role=\"Gen AI eng.\",\n",
    "    affiliation=\"OpenAI\",\n",
    "    description=\"Focus on building and deploying generative AI models.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0046c990",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Analyst(name='klangat', role='Gen AI eng.', affiliation='OpenAI', description='Focus on building and deploying generative AI models.')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "038f2661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: klangat\n",
      "Role: Gen AI eng.\n",
      "Affiliation: OpenAI\n",
      "Description: Focus on building and deploying generative AI models.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(analyst.persona)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0be5bdac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Gen AI eng.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyst.role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3f0d1ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'OpenAI'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyst.affiliation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "49549c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenerateAnalystsState(TypedDict):\n",
    "    \"\"\"_summary_\n",
    "    \"\"\"\n",
    "    topic: str\n",
    "    max_analysts: int\n",
    "    human_analyst_feedback: str\n",
    "    analysts: List[Analyst]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3d811945",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'topic': 'AI in healthcare',\n",
       " 'max_analysts': 5,\n",
       " 'human_analyst_feedback': 'give the real information'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GenerateAnalystsState(\n",
    "    topic=\"AI in healthcare\",\n",
    "    max_analysts=5,\n",
    "    human_analyst_feedback=\"give the real information\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0b7b8b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyst_instructions = \"\"\"You are tasked with creating a set of AI analyst personas. Follow these instructions carefully:\n",
    "\n",
    "1. First, review the research topic:\n",
    "{topic}\n",
    "        \n",
    "2. Examine any editorial feedback that has been optionally provided to guide creation of the analysts: \n",
    "        \n",
    "{human_analyst_feedback}\n",
    "    \n",
    "3. Determine the most interesting themes based upon documents and / or feedback above.\n",
    "                    \n",
    "4. Pick the top {max_analysts} themes.\n",
    "\n",
    "5. Assign one analyst to each theme.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7f1fcc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_analyst(state):\n",
    "    \"\"\"It is creating my analyst\n",
    "    \"\"\"\n",
    "    topic = state[\"topic\"]\n",
    "    max_analysts = state[\"max_analysts\"]\n",
    "    human_analyst_feedback = state.get(\"human_analyst_feedback\", \"\")\n",
    "\n",
    "    structured_llm = llm.with_structured_output(Perspective)\n",
    "\n",
    "    system_messages = analyst_instructions.format(\n",
    "        topic=topic,\n",
    "        max_analysts=max_analysts,\n",
    "        human_analyst_feedback=human_analyst_feedback\n",
    "    )\n",
    "\n",
    "    analysts = structured_llm.invoke([SystemMessage(content=system_messages)] + [HumanMessage(content=\"Generate the set of analysts\")])\n",
    "\n",
    "    # write the list of analysis to state\n",
    "    return{\"analysts\": analysts.analysts}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "25548b22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['You are tasked with creating a set of AI analyst personas. Follow these instructions carefully:\\n\\n1. First, review the research topic:\\nAI in healthcare\\n\\n2. Examine any editorial feedback that has been optionally provided to guide creation of the analysts: \\n\\nplease expalain only on AI\\n\\n3. Determine the most interesting themes based upon documents and / or feedback above.\\n\\n4. Pick the top 4 themes.\\n\\n5. Assign one analyst to each theme.', 'Generate the set of analysts.']\n"
     ]
    }
   ],
   "source": [
    "print([analyst_instructions.format(\n",
    "    topic=\"AI in healthcare\",\n",
    "    max_analysts=4,\n",
    "    human_analyst_feedback=\"please expalain only on AI\"\n",
    ")] + [\"Generate the set of analysts.\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5c67e871",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'analysts': [Analyst(name='Dr. Rachel Kim', role='Medical Researcher', affiliation='Harvard Medical School', description='Focus on AI applications in disease diagnosis and treatment, with concerns about data privacy and algorithmic bias.'),\n",
       "  Analyst(name='Dr. Liam Chen', role='Healthcare Policy Analyst', affiliation='World Health Organization', description='Examines the impact of AI on healthcare policy and regulation, with a focus on accessibility and equity.'),\n",
       "  Analyst(name='Dr. Maya Patel', role='AI Ethics Specialist', affiliation='MIT Media Lab', description='Investigates the ethical implications of AI in healthcare, including issues of transparency, accountability, and patient autonomy.'),\n",
       "  Analyst(name='Dr. Ethan Hall', role='Clinical Informatics Specialist', affiliation='Stanford Health Care', description='Explores the integration of AI into clinical decision support systems and electronic health records, with a focus on improving patient outcomes and streamlining clinical workflows.')]}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_analyst(\n",
    "    {'topic': 'AI in healthcare',\n",
    "    'max_analysts': 4,\n",
    "    'human_analyst_feedback': 'give the real information'}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f4ac95d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def human_feedback(state):\n",
    "    \"\"\" No op node that should be interrupted on \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5cfb4fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def should_continue(state):\n",
    "    \"\"\" summanry\"\"\"\n",
    "    feedback = (state.get(\"human_analyst_feedback\") or \"\").strip().lower()\n",
    "    if feedback and feedback not in [\"\", \"none\", \"no\", \"nope\", \"skip\", \"done\", \"continue\"]:\n",
    "        return \"create_analyst\"\n",
    "    return END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "671db5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown, Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "93e84615",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = StateGraph(GenerateAnalystsState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8489c7bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x1f1df7e3dd0>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "builder.add_node(\"create_analyst\", create_analyst)\n",
    "builder.add_node(\"human_feedback\", human_feedback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f5ed7190",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x1f1df7e3dd0>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "builder.add_edge(START, \"create_analyst\")\n",
    "builder.add_edge(\"create_analyst\", \"human_feedback\")\n",
    "builder.add_conditional_edges(\"human_feedback\",\n",
    "                               should_continue,\n",
    "                               [\"create_analyst\",\n",
    "                                END])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4849cd89",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = MemorySaver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1dc27620",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = builder.compile(interrupt_before= [\"human_feedback\"], checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f2799fb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Image(graph.get_graph(xray=1).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0fe659b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic = \"The benefits of adopting Langgraph as an agent Framework over Autogen\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d3bac431",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_analysts = 4\n",
    "thread = {\"configurable\": {\"thread_id\": 1}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "302e75cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Dr. Rachel Kim\n",
      "Role: AI Researcher\n",
      "Affiliation: Stanford University\n",
      "Description: Expert in natural language processing and agent frameworks, focusing on the benefits of Langgraph's flexibility and customizability\n",
      "--------------------------------------------------\n",
      "Name: Dr. Liam Chen\n",
      "Role: Software Engineer\n",
      "Affiliation: Google\n",
      "Description: Specialist in developing conversational AI systems, concerned with the scalability and reliability of Autogen compared to Langgraph\n",
      "--------------------------------------------------\n",
      "Name: Dr. Ava Moreno\n",
      "Role: Cognitive Scientist\n",
      "Affiliation: MIT\n",
      "Description: Researcher in human-computer interaction, interested in the potential of Langgraph to enhance user experience and interface design\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Name: Dr. Julian Lee\n",
      "Role: Tech Consultant\n",
      "Affiliation: Deloitte\n",
      "Description: Advisor on AI adoption and implementation, evaluating the cost-benefit analysis and feasibility of integrating Langgraph into existing infrastructure\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Alex Chen\n",
      "Role: Startup Founder\n",
      "Affiliation: TechStars\n",
      "Description: Focus on the benefits of adopting Langgraph for startup companies, particularly in terms of scalability and cost-effectiveness.\n",
      "--------------------------------------------------\n",
      "Name: Dr. Rachel Kim\n",
      "Role: Enterprise Architect\n",
      "Affiliation: Gartner\n",
      "Description: Examine the latest enterprise applications of Langgraph and its potential to replace Autogen in large-scale industries.\n",
      "--------------------------------------------------\n",
      "Name: Mayank Singh\n",
      "Role: Technical Lead\n",
      "Affiliation: Microsoft\n",
      "Description: Investigate the technical advantages of Langgraph over Autogen, including its performance, security, and integration capabilities.\n",
      "--------------------------------------------------\n",
      "Name: Emily Patel\n",
      "Role: Innovation Consultant\n",
      "Affiliation: Accenture\n",
      "Description: Explore the innovative use cases of Langgraph in various industries, such as healthcare and finance, and its potential to drive digital transformation.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for event in graph.stream({\"topic\":topic,\n",
    "            \"max_analysts\":max_analysts},\n",
    "            thread,\n",
    "            stream_mode= \"values\"):\n",
    "    analysts = event.get('analysts', '')\n",
    "\n",
    "    if analysts:\n",
    "        for analyst in analysts:\n",
    "            print(f\"Name: {analyst.name}\")\n",
    "            print(f\"Role: {analyst.role}\")\n",
    "            print(f\"Affiliation: {analyst.affiliation}\")\n",
    "            print(f\"Description: {analyst.description}\")\n",
    "            print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4ec2f68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = graph.get_state(thread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "04be876b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StateSnapshot(values={'topic': 'The benefits of adopting Langgraph as an agent Framework over Autogen', 'max_analysts': 4, 'analysts': [Analyst(name='Dr. Rachel Kim', role='AI Researcher', affiliation='Stanford University', description=\"Expert in natural language processing and agent frameworks, focusing on the benefits of Langgraph's flexibility and customizability\"), Analyst(name='Dr. Liam Chen', role='Software Engineer', affiliation='Google', description='Specialist in developing conversational AI systems, concerned with the scalability and reliability of Autogen compared to Langgraph'), Analyst(name='Dr. Ava Moreno', role='Cognitive Scientist', affiliation='MIT', description='Researcher in human-computer interaction, interested in the potential of Langgraph to enhance user experience and interface design'), Analyst(name='Dr. Julian Lee', role='Tech Consultant', affiliation='Deloitte', description='Advisor on AI adoption and implementation, evaluating the cost-benefit analysis and feasibility of integrating Langgraph into existing infrastructure')]}, next=('human_feedback',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0a7466-1dde-6f5a-8001-345c7c86d7e7'}}, metadata={'source': 'loop', 'step': 1, 'parents': {}}, created_at='2025-10-12T08:35:17.996937+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0a7466-0f3c-66b0-8000-bde660c071ae'}}, tasks=(PregelTask(id='17f88063-513d-dfbe-1c61-5bd69f3f1838', name='human_feedback', path=('__pregel_pull', 'human_feedback'), error=None, interrupts=(), state=None, result=None),), interrupts=())"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7080e35a",
   "metadata": {},
   "source": [
    "StateSnapshot(values={'topic': 'The benefits of adopting Langgraph as an agent Framework over Autogen', 'max_analysts': 4, 'analysts': [Analyst(name='Dr. Rachel Kim', role='AI Researcher', affiliation='Stanford University', description=\"Expert in natural language processing and agent frameworks, focusing on the benefits of Langgraph's flexibility and customizability\"), Analyst(name='Dr. Liam Chen', role='Software Engineer', affiliation='Google', description='Specialist in developing conversational AI systems, concerned with the scalability and reliability of Autogen compared to Langgraph'), Analyst(name='Dr. Ava Moreno', role='Cognitive Scientist', affiliation='MIT', description='Researcher in human-computer interaction, interested in the potential of Langgraph to enhance user experience and interface design'), Analyst(name='Dr. Julian Lee', role='Tech Consultant', affiliation='Deloitte', description='Advisor on AI adoption and implementation, evaluating the cost-benefit analysis and feasibility of integrating Langgraph into existing infrastructure')]}, next=('human_feedback',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0a7466-1dde-6f5a-8001-345c7c86d7e7'}}, metadata={'source': 'loop', 'step': 1, 'parents': {}}, created_at='2025-10-12T08:35:17.996937+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0a7466-0f3c-66b0-8000-bde660c071ae'}}, tasks=(PregelTask(id='17f88063-513d-dfbe-1c61-5bd69f3f1838', name='human_feedback', path=('__pregel_pull', 'human_feedback'), error=None, interrupts=(), state=None, result=None),), interrupts=())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e7593125",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('human_feedback',)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check attribute- next\n",
    "state.next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e8805aba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'configurable': {'thread_id': '1',\n",
       "  'checkpoint_ns': '',\n",
       "  'checkpoint_id': '1f0a765e-c11e-6d49-8002-8d3c40667c68'}}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.update_state(thread,\n",
    "                   {\"human_analyst_feedback\": \"add some start up perspective and focus on latest enterprise application.\"}, as_node=\"human_feedback\"\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9c7dcf68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we are satisfied, then we simply supply no feedback\n",
    "further_feedback = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d857fa78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Get the latest state (you're paused at 'human_feedback')\n",
    "state = graph.get_state(thread)\n",
    "\n",
    "# 2) Use the exact config from that state (it already has thread_id, checkpoint_ns, checkpoint_id)\n",
    "cfg = state.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e325ae2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'configurable': {'thread_id': '1',\n",
       "  'checkpoint_ns': '',\n",
       "  'checkpoint_id': '1f0a773a-218b-6086-8006-b24b9d61eecd'}}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3) Update feedback at the 'human_feedback' node\n",
    "#    Tip: if your TypedDict says `human_analyst_feedback: str`, prefer \"\" (empty string) over None\n",
    "graph.update_state(cfg, {\"human_analyst_feedback\": \"\"}, as_node=\"human_feedback\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0551e8ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "()\n"
     ]
    }
   ],
   "source": [
    "# 4) Verify it moved to END\n",
    "final_state = graph.get_state(thread)\n",
    "print(final_state.next) # should be (END,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fec23209",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Analyst(name='Alex Chen', role='Startup Founder', affiliation='TechStars', description='Focus on the benefits of adopting Langgraph for startup companies, particularly in terms of scalability and cost-effectiveness.'),\n",
       " Analyst(name='Dr. Rachel Kim', role='Enterprise Architect', affiliation='Gartner', description='Examine the latest enterprise applications of Langgraph and its potential to replace Autogen in large-scale industries.'),\n",
       " Analyst(name='Mayank Singh', role='Technical Lead', affiliation='Microsoft', description='Investigate the technical advantages of Langgraph over Autogen, including its performance, security, and integration capabilities.'),\n",
       " Analyst(name='Emily Patel', role='Innovation Consultant', affiliation='Accenture', description='Explore the innovative use cases of Langgraph in various industries, such as healthcare and finance, and its potential to drive digital transformation.')]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysts = final_state.values.get(\"analysts\")\n",
    "analysts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e0551438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Alex Chen\n",
      "Role: Startup Founder\n",
      "Affiliation: TechStars\n",
      "Description: Focus on the benefits of adopting Langgraph for startup companies, particularly in terms of scalability and cost-effectiveness.\n",
      "--------------------------------------------------\n",
      "Name: Dr. Rachel Kim\n",
      "Role: Enterprise Architect\n",
      "Affiliation: Gartner\n",
      "Description: Examine the latest enterprise applications of Langgraph and its potential to replace Autogen in large-scale industries.\n",
      "--------------------------------------------------\n",
      "Name: Mayank Singh\n",
      "Role: Technical Lead\n",
      "Affiliation: Microsoft\n",
      "Description: Investigate the technical advantages of Langgraph over Autogen, including its performance, security, and integration capabilities.\n",
      "--------------------------------------------------\n",
      "Name: Emily Patel\n",
      "Role: Innovation Consultant\n",
      "Affiliation: Accenture\n",
      "Description: Explore the innovative use cases of Langgraph in various industries, such as healthcare and finance, and its potential to drive digital transformation.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for analyst in analysts:\n",
    "    print(f\"Name: {analyst.name}\")\n",
    "    print(f\"Role: {analyst.role}\")\n",
    "    print(f\"Affiliation: {analyst.affiliation}\")\n",
    "    print(f\"Description: {analyst.description}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1066220b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    "from langgraph.checkpoint.memory import MemorySaver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aadbf9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WikipediaLoader\n",
    "\n",
    "docs = WikipediaLoader(query=\"LangGraph\").load()\n",
    "print(docs[0].page_content[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f5f69bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloud computing is \"a paradigm for enabling network access to a scalable and elastic pool of shareable physical or virtual resources with self-service provisioning and administration on-demand,\" according to ISO. It is commonly referred to as \"the cloud\".\n",
      "\n",
      "\n",
      "== Characteristics ==\n",
      "In 2011, the National Institute of Standards and Technology (NIST) identified five \"essential characteristics\" for cloud systems. Below are the exact definitions according to NIST:\n",
      "\n",
      "On-demand self-service: \"A consumer ca\n"
     ]
    }
   ],
   "source": [
    "docs = WikipediaLoader(query=\"The benefits of adopting AWS cloud\").load()\n",
    "print(docs[0].page_content[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "db681be3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page: Semantic Web\n",
      "Summary: The Semantic Web, sometimes known as Web 3.0, is an extension of the World Wide Web through standards set by the World Wide Web Consortium (W3C). The goal of the Semantic Web is to make Internet data machine-readable.\n",
      "To enable the encoding of semantics with the data, technologies such as Resource Description Framework (RDF) and Web Ontology Language (OWL) are used. These technologies are used to formally represent metadata. For example, ontology can describe concepts, relationships between entities, and categories of things. These embedded semantics offer significant advantages such as reasoning over data and operating with heterogeneous data sources.\n",
      "These standards promote common data formats and exchange protocols on the Web, fundamentally the RDF. According to the W3C, \"The Semantic Web provides a common framework that allows data to be shared and reused across application, enterprise, and community boundaries.\" The Semantic Web is therefore regarded as an integrator across different content and information applications and systems.\n",
      "\n",
      "\n",
      "\n",
      "Page: React (software)\n",
      "Summary: React (also known as React.js or ReactJS) is a free and open-source front-end JavaScript library that aims to make building user interfaces based on components more \"seamless\". It is maintained by Meta (formerly Facebook) and a community of individual developers and companies. According to the Stack Overflow Developer Survey, React is one of the most commonly used web technologies.\n",
      "React can be used to develop single-page, mobile, or server-rendered applications with frameworks like Next.js and React Router. Because React is only concerned with the user interface and rendering components to the DOM, React applications often rely on libraries for routing and other client-side functionality. A key advantage of React is that it only re-renders those parts of the page that have changed, avoiding unnecessary re-rendering of unchanged DOM elements. React is used by an estimated 6% of all websites.\n",
      "\n",
      "Page: Deep learning\n",
      "Summary: In machine learning, deep learning focuses on utilizing multilayered neural networks to perform tasks such as classification, regression, and representation learning. The field takes inspiration from biological neuroscience and is centered around stacking artificial neurons into layers and \"training\" them to process data. The adjective \"deep\" refers to the use of multiple layers (ranging from three to several hundred or thousands) in the network. Methods used can be supervised, semi-supervised or unsupervised.\n",
      "Some common deep learning network architectures include fully connected networks, deep belief networks, recurrent neural networks, convolutional neural networks, generative adversarial networks, transformers, and neural radiance fields. These architectures have been applied to fields including computer vision, speech recognition, natural language processing, machine translation, bioinformatics, drug design, medical image analysis, climate science, material inspection and board game programs, where they have produced results comparable to and in some cases surpassing human expert performance.\n",
      "Early forms of neural networks were inspired by information processing and distributed communication nodes in biological systems, particularly the human brain. However, current neural networks do not intend to model the brain function of organisms, and are generally seen as low-quality models for that purpose.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "wiki = WikipediaAPIWrapper(doc_content_chars_max=4000)\n",
    "docs = wiki.run(\"The benefits of adopting LangGraph as an agentic framework\")\n",
    "print(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9833957",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    "from langgraph.checkpoint.memory import MemorySaver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f24c9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8241e5ef",
   "metadata": {},
   "source": [
    "#### Second Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66a163e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d7fb97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()  # take environment variables from .env.\n",
    "import os\n",
    "tavily_api_key = os.getenv(\"TAVILY_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec38e14c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_23960\\3682967505.py:1: LangChainDeprecationWarning: The class `TavilySearchResults` was deprecated in LangChain 0.3.25 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-tavily package and should be used instead. To use it run `pip install -U :class:`~langchain-tavily` and import as `from :class:`~langchain_tavily import TavilySearch``.\n",
      "  tavily_search = TavilySearchResults(tavily_api_key=tavily_api_key)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'title': 'What is LangGraph? - GeeksforGeeks',\n",
       "  'url': 'https://www.geeksforgeeks.org/machine-learning/what-is-langgraph/',\n",
       "  'content': 'LangGraph is an open-source framework built by LangChain that streamlines the creation and management of AI agent workflows. At its core, LangGraph combines large language models (LLMs) with graph-based architectures allowing developers to map, organize and optimize how AI agents interact and make decisions.',\n",
       "  'score': 0.9294982},\n",
       " {'title': 'What is LangGraph? - Analytics Vidhya',\n",
       "  'url': 'https://www.analyticsvidhya.com/blog/2024/07/langgraph-revolutionizing-ai-agent/',\n",
       "  'content': 'To sum up, LangGraph is a major advancement in the development of AI agents. It enables developers to push the limits of whats possible with AI agents by eliminating the shortcomings of earlier systems and offering a flexible, graph-based framework for agent construction and execution. LangGraph is positioned to influence the direction of artificial intelligence significantly in the future. [...] LangGraph is a library built on top of Langchain that is designed to facilitate the creation of cyclic graphs for large language model (LLM)  based AI agents.\\n   It views agent Objective Points about LangGraph and workflows as cyclic graph topologies, allowing for more variable and nuanced agent behaviors than linear execution models. [...] Frameworks such as LangGraph are becoming increasingly important as AI develops. LangGraph is making the next generation of AI applications possible by offering a versatile and strong framework for developing and overseeing AI agents.',\n",
       "  'score': 0.92005306},\n",
       " {'title': 'LangGraph Tutorial: What Is LangGraph and How to Use It?',\n",
       "  'url': 'https://www.datacamp.com/tutorial/langgraph-tutorial',\n",
       "  'content': \"LangGraph is a library within the LangChain ecosystem designed to tackle these challenges head-on. LangGraph provides a framework for defining, coordinating, and executing multiple LLM agents (or chains) in a structured manner.\\n\\nIt simplifies the development process by enabling the creation of cyclical graphs, which are essential for developing agent runtimes. With LangGraph, we can easily build robust, scalable, and flexible multi-agent systems. [...] For applications requiring autonomous decision-making, LangGraph enables the creation of agents that can perform tasks independently based on user inputs and predefined logic.\\n\\nThese agents can execute complex workflows, interact with other systems, and adapt to new information dynamically. LangGraph's structured framework ensures that each agent operates efficiently and effectively, making it suitable for tasks like automated customer support, data processing, and system monitoring. [...] In educational platforms, LangGraph can be used to create adaptive learning environments that cater to individual learning styles and needs. Multiple agents can assess a student's progress, provide customized exercises, and offer real-time feedback. The stateful nature of LangGraph ensures that the system retains information about each learner's performance and preferences, enabling a more personalized and effective educational experience.\\n\\nConclusion\",\n",
       "  'score': 0.9183121},\n",
       " {'title': 'What is LangGraph? Key Concepts, Use Cases, and How to Get ...',\n",
       "  'url': 'https://www.designveloper.com/blog/what-is-langgraph/',\n",
       "  'content': 'LangGraph is an open-source library from the LangChain team and free to use. It can be used in Python as well as JavaScript environments, which means that it can be used by a large number of developers. In contrast to more basic chain-based systems, LangGraph is a graph-based system that coordinates AI workflows. This means that instead of a linear sequence of steps, an application is modeled as a directed graph of nodes and edges.\\n\\nImage 42: LangGraph at a Glance [...] Imagine creating an AI application in which several language model agents collaborate on a complex task. It may be difficult to coordinate these agents, keep context across steps and achieve reliable results. LangGraph is a tool for solving this challenge. It is a framework on LangChain ecosystem that gives a way to define, coordinate, and execute multiple LLM (Large Language Model) agents in complex workflows. In other words, for anyone wondering what is LangGraph, it is a stateful [...] workflow continues. To put it briefly, LangGraph is about coordinating various AI elements to operate in coordination, have memory of previous interactions, and enable complex control flows within an application.',\n",
       "  'score': 0.9020676},\n",
       " {'title': \"Introduction to LangGraph: A Beginner's Guide - Medium\",\n",
       "  'url': 'https://medium.com/@cplog/introduction-to-langgraph-a-beginners-guide-14f9be027141',\n",
       "  'content': 'LangGraph is a library built on top of LangChain, designed to add cyclic computational capabilities to your LLM applications. While LangChain allows you to define chains of computation (Directed Acyclic Graphs or DAGs), LangGraph introduces the ability to add cycles, enabling more complex, agent-like behaviors where you can call an LLM in a loop, asking it what action to take next.\\n\\nKey Concepts [...] Stateful Graph: LangGraph revolves around the concept of a stateful graph, where each node in the graph represents a step in your computation, and the graph maintains a state that is passed around and updated as the computation progresses.\\n   Nodes: Nodes are the building blocks of your LangGraph. Each node represents a function or a computation step. You define nodes to perform specific tasks, such as processing input, making decisions, or interacting with external APIs.',\n",
       "  'score': 0.8921218}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tavily_search = TavilySearchResults(tavily_api_key=tavily_api_key)\n",
    "tavily_search.invoke(\"langgraph\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0dd6d8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WikipediaLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b620b88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain is a software framework that helps facilitate the integration of large language models (LLMs) into applications. As a language model integration framework, LangChain's use-cases largely over\n"
     ]
    }
   ],
   "source": [
    "docs = WikipediaLoader(query=\"LangGraph\").load()\n",
    "print(docs[0].page_content[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6691c6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, List\n",
    "import operator\n",
    "from typing_extensions import TypedDict\n",
    "from pydantic import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7cdd540",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InterviewState(MessagesState):\n",
    "    \"\"\" \n",
    "    \"\"\"\n",
    "    max_num_turn: int\n",
    "    context: Annotated[list, operator.add]\n",
    "    analyst: Analyst\n",
    "    interview: str\n",
    "    sections: list\n",
    "\n",
    "class SearchQuery(BaseModel):\n",
    "    \"\"\"_summary_\n",
    "    \"\"\"\n",
    "    search_query: str = Field(None, description=\"Search query for retrieval.\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "716d5ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = {\"max_num_turns\":2, \"context\":[], \"analyst\":analyst, \"interview\":\"\",\"section\":\"\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6f31d6f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_num_turns': 2,\n",
       " 'context': [],\n",
       " 'analyst': Analyst(name='klangat', role='Gen AI eng.', affiliation='OpenAI', description='Focus on building and deploying generative AI models.'),\n",
       " 'interview': '',\n",
       " 'section': ''}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f822344",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a62801a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_instructions = \"\"\"You are an analyst tasked with interviewing an expert to learn about a specific topic. \n",
    "\n",
    "Your goal is boil down to interesting and specific insights related to your topic.\n",
    "\n",
    "1. Interesting: Insights that people will find surprising or non-obvious.\n",
    "        \n",
    "2. Specific: Insights that avoid generalities and include specific examples from the expert.\n",
    "\n",
    "Here is your topic of focus and set of goals: {goals}\n",
    "        \n",
    "Begin by introducing yourself using a name that fits your persona, and then ask your question.\n",
    "\n",
    "Continue to ask questions to drill down and refine your understanding of the topic.\n",
    "        \n",
    "When you are satisfied with your understanding, complete the interview with: \"Thank you so much for your help!\"\n",
    "\n",
    "Remember to stay in character throughout your response, reflecting the persona and goals provided to you.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e6921117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: klangat\n",
      "Role: Gen AI eng.\n",
      "Affiliation: OpenAI\n",
      "Description: Focus on building and deploying generative AI models.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(analyst.persona)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "275d9909",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You are an analyst tasked with interviewing an expert to learn about a specific topic. \\n\\nYour goal is boil down to interesting and specific insights related to your topic.\\n\\n1. Interesting: Insights that people will find surprising or non-obvious.\\n\\n2. Specific: Insights that avoid generalities and include specific examples from the expert.\\n\\nHere is your topic of focus and set of goals: Name: klangat\\nRole: Gen AI eng.\\nAffiliation: OpenAI\\nDescription: Focus on building and deploying generative AI models.\\n\\n\\nBegin by introducing yourself using a name that fits your persona, and then ask your question.\\n\\nContinue to ask questions to drill down and refine your understanding of the topic.\\n\\nWhen you are satisfied with your understanding, complete the interview with: \"Thank you so much for your help!\"\\n\\nRemember to stay in character throughout your response, reflecting the persona and goals provided to you.'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_instructions.format(goals = analyst.persona)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ff328d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_question(state:InterviewState):\n",
    "    \"\"\"Node to generate the questions\"\"\"\n",
    "    # get state\n",
    "    analyst = state[\"analyst\"]\n",
    "    messages = state[\"messages\"]\n",
    "\n",
    "    # generate the question\n",
    "    system_message = question_instructions.format(goals = analyst.persona)\n",
    "    question = llm.invoke([SystemMessage(content=system_message)] + messages)\n",
    "\n",
    "    # return the question through state\n",
    "    return {\"messages\": [question]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "3b6cfb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "interview_builder = StateGraph(InterviewState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d52a6071",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import get_buffer_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "b87af106",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search query writing\n",
    "search_instructions = SystemMessage(content=f\"\"\"You will be given a conversation between an analyst and an expert. \n",
    "Your goal is to generate a well-structured query for use in retrieval and / or web-search related to the conversation. \n",
    "First, analyze the full conversation.\n",
    "Pay particular attention to the final question posed by the analyst.\n",
    "Convert this final question into a well-structured web search query\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d9de1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c03f369",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_question(state:InterviewState):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        state (InterviewState): _description_\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "65e2967b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_web(state:InterviewState):\n",
    "    \"\"\"\n",
    "    Retrieve data from the web.\n",
    "    \"\"\"\n",
    "    structure_llm = llm.with_structured_output(SearchQuery)\n",
    "    search_query = structure_llm.invoke([search_instructions]+[\"messages\"])\n",
    "\n",
    "    # Search\n",
    "    search_docs = tavily_search.invoke(search_query.search_query)\n",
    "\n",
    "    # Format\n",
    "    formatted_search_docs = \"\\n\\n---\\n\\n\".join(\n",
    "        {\n",
    "            f'<Document href=\"{doc[\"url\"]}\"/>\\n{doc[\"content\"]}\\n</Document>'\n",
    "            for doc in search_docs\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return {\"context\": [formatted_search_docs]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "1dfd1839",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_wikipedia(state:InterviewState):\n",
    "    \"\"\"Retrieve data from wikipedia\"\"\"\n",
    "    \n",
    "    # Search query\n",
    "    structured_llm = llm.with_structured_output(SearchQuery)\n",
    "    search_query = structured_llm.invoke([search_instructions]+state[\"messages\"])\n",
    "\n",
    "    print(\"*\" * 50)\n",
    "    print(search_query)\n",
    "    # Search\n",
    "    search_docs = WikipediaLoader(query=search_query.search_query,\n",
    "                                  load_max_docs=2).load()\n",
    "    \n",
    "    # Format\n",
    "    formatted_search_docs = \"\\n\\n---\\n\\n\".join(\n",
    "        {\n",
    "            f'<Document source=\"{doc.metadata[\"source\"]}\" page=\"{doc.metadata.get(\"page\", \"\")}\"/>\\n{doc.page_content}\\n</Document>'\n",
    "            for doc in search_docs\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return {\"context\": [formatted_search_docs]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "5d0a9040",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_instructions = \"\"\"You are an expert being interviewed by an analyst.\n",
    "\n",
    "Here is analyst area of focus: {goals}. \n",
    "        \n",
    "You goal is to answer a question posed by the interviewer.\n",
    "\n",
    "To answer question, use this context:\n",
    "        \n",
    "{context}\n",
    "\n",
    "When answering questions, follow these guidelines:\n",
    "        \n",
    "1. Use only the information provided in the context. \n",
    "        \n",
    "2. Do not introduce external information or make assumptions beyond what is explicitly stated in the context.\n",
    "\n",
    "3. The context contain sources at the topic of each individual document.\n",
    "\n",
    "4. Include these sources your answer next to any relevant statements. For example, for source # 1 use [1]. \n",
    "\n",
    "5. List your sources in order at the bottom of your answer. [1] Source 1, [2] Source 2, etc\n",
    "        \n",
    "6. If the source is: <Document source=\"assistant/docs/llama3_1.pdf\" page=\"7\"/>' then just list: \n",
    "        \n",
    "[1] assistant/docs/llama3_1.pdf, page 7 \n",
    "        \n",
    "And skip the addition of the brackets as well as the Document source preamble in your citation.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "9b338ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer(state:InterviewState):\n",
    "    \"\"\"\n",
    "    Node to answer a question\n",
    "    \"\"\"\n",
    "    # Get state\n",
    "    analyst = state[\"analyst\"]\n",
    "    messages = state[\"messages\"]\n",
    "    context = state[\"context\"]\n",
    "\n",
    "    # Answer question\n",
    "    system_message = answer_instructions.format(goals = analyst.persona, context=context)\n",
    "    answer = llm.invoke([SystemMessage(content=system_message)] + messages)\n",
    "\n",
    "    # Name the message as coming from the expert\n",
    "    answer.name = \"expert\"\n",
    "\n",
    "    # Append it to the state\n",
    "    return {\"messages\": [answer]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "6ca33f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def router_message(state:InterviewState, name: str = \"expert\"):\n",
    "    \"\"\"\n",
    "    Router between question and answer.\n",
    "    \"\"\"\n",
    "    # Get messages\n",
    "    messages = state[\"messages\"]\n",
    "    max_num_turns = state.get(\"max_num_turns\", 2)\n",
    "\n",
    "    # Check the number of expert answers\n",
    "    num_responses = len(\n",
    "        [m for m in messages if isinstance(m, AIMessage) and m.name == name]\n",
    "    )\n",
    "\n",
    "    # end if expert has answered more than the max turns\n",
    "    if num_responses >= max_num_turns:\n",
    "        return \"save_interview\"\n",
    "    \n",
    "    # This router is run after each question - answer pair\n",
    "    # Get the last question ased to check if it is the end of the discussion\n",
    "    last_question = messages[-2]\n",
    "\n",
    "    if \"Thank you so much for your help\" in last_question.content:\n",
    "        return 'save_interview'\n",
    "    \n",
    "    return \"ask_question\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d13bdd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_interview(state:InterviewState):\n",
    "    \"\"\"\n",
    "    Save interview\n",
    "    \"\"\"\n",
    "    # Get messages\n",
    "    messages = state[\"messages\"]\n",
    "\n",
    "    # Cnvert interview to a string\n",
    "    interview = get_buffer_string(messages)\n",
    "\n",
    "    # Save to interviews key\n",
    "    return {\"interview\": interview}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "829a4fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "section_writer_instructions = \"\"\"You are an expert technical writer. \n",
    "            \n",
    "Your task is to create a short, easily digestible section of a report based on a set of source documents.\n",
    "\n",
    "1. Analyze the content of the source documents: \n",
    "- The name of each source document is at the start of the document, with the <Document tag.\n",
    "        \n",
    "2. Create a report structure using markdown formatting:\n",
    "- Use ## for the section title\n",
    "- Use ### for sub-section headers\n",
    "        \n",
    "3. Write the report following this structure:\n",
    "a. Title (## header)\n",
    "b. Summary (### header)\n",
    "c. Sources (### header)\n",
    "\n",
    "4. Make your title engaging based upon the focus area of the analyst: \n",
    "{focus}\n",
    "\n",
    "5. For the summary section:\n",
    "- Set up summary with general background / context related to the focus area of the analyst\n",
    "- Emphasize what is novel, interesting, or surprising about insights gathered from the interview\n",
    "- Create a numbered list of source documents, as you use them\n",
    "- Do not mention the names of interviewers or experts\n",
    "- Aim for approximately 400 words maximum\n",
    "- Use numbered sources in your report (e.g., [1], [2]) based on information from source documents\n",
    "        \n",
    "6. In the Sources section:\n",
    "- Include all sources used in your report\n",
    "- Provide full links to relevant websites or specific document paths\n",
    "- Separate each source by a newline. Use two spaces at the end of each line to create a newline in Markdown.\n",
    "- It will look like:\n",
    "\n",
    "### Sources\n",
    "[1] Link or Document name\n",
    "[2] Link or Document name\n",
    "\n",
    "7. Be sure to combine sources. For example this is not correct:\n",
    "\n",
    "[3] https://ai.meta.com/blog/meta-llama-3-1/\n",
    "[4] https://ai.meta.com/blog/meta-llama-3-1/\n",
    "\n",
    "There should be no redundant sources. It should simply be:\n",
    "\n",
    "[3] https://ai.meta.com/blog/meta-llama-3-1/\n",
    "        \n",
    "8. Final review:\n",
    "- Ensure the report follows the required structure\n",
    "- Include no preamble before the title of the report\n",
    "- Check that all guidelines have been followed\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "e28c8af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_section(state:InterviewState):\n",
    "    \"\"\"\n",
    "    Node to answer a question\n",
    "    \"\"\"\n",
    "    # Get state\n",
    "    interview = state[\"interview\"]\n",
    "    context = state[\"context\"]\n",
    "    analyst = state[\"analyst\"]\n",
    "\n",
    "    # Write section using either the gathered source docs from interview (context) or the interview itself (interview)\n",
    "    system_message = section_writer_instructions.format(focus = analyst.description)\n",
    "    section = llm.invoke([SystemMessage(content=system_message)] +\n",
    "                          [HumanMessage(content=f\"Use this source to write your section: {context}\")])\n",
    "    \n",
    "    # Append it to state\n",
    "    return {\"sections\": [section.content]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "30f5bfbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x2592e806fd0>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interview_builder.add_node(\"ask_question\", generate_question)\n",
    "interview_builder.add_node(\"search_web\", search_web)\n",
    "interview_builder.add_node(\"search_wikipedia\", search_wikipedia)\n",
    "interview_builder.add_node(\"generate_answer\", generate_answer)\n",
    "interview_builder.add_node(\"save_interview\", save_interview)\n",
    "interview_builder.add_node(\"write_section\", write_section)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "eace526c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x2592e806fd0>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interview_builder.add_edge(START, \"ask_question\")\n",
    "interview_builder.add_edge(\"ask_question\", \"search_web\")\n",
    "interview_builder.add_edge(\"ask_question\", \"search_wikipedia\")\n",
    "interview_builder.add_edge(\"search_web\", \"generate_answer\")\n",
    "interview_builder.add_edge(\"search_wikipedia\", \"generate_answer\")\n",
    "interview_builder.add_conditional_edges(\"generate_answer\",\n",
    "                           router_message,\n",
    "                           [\"ask_question\",\n",
    "                            \"save_interview\"])\n",
    "interview_builder.add_edge(\"save_interview\", \"write_section\")\n",
    "interview_builder.add_edge(\"write_section\", END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "b23577bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = MemorySaver()\n",
    "interview_graph = interview_builder.compile(checkpointer=memory).with_config(run_name = \"Conduct Interview\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "93d369ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown, Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "91dd887f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAJ2CAIAAADNP57VAAAQAElEQVR4nOydB0AURxfHZ/fovQkICohdURG7n7H3Emss0dhjN9bYe++aWKMmMbaosWvsvcUuiL0XmgWRDnfc7vf2Fs7jgIPDu+Xu9v2Cl73Z2dk289/33szNmrEsSxAEQXSHGUEQBNEpKCsIgugYlBUEQXQMygqCIDoGZQVBEB2DsoIgiI5BWUEMCTm5cepz1Ovk5ERGJpWnpbAsBaksBf+jCaXIwsJ/DAVfYIGiKMJwiRRNGDn3CekMw0JeWGYZbkuJhGLSCKG5rZSJNEWxXEGEYjM2ZxXlc0mKfVAM5FKs4sZgwI5YhqSvVxSlPGSJBZGY01Y2Zi7u5gH/c3AtbEFED4XjVhBD4MBvER/DUlOS5GbmtIW1xMKSlpgTaRJIBacg0OhpM6Jo2Iq2z2sAJyqKZa6pK2oyq1jgsrGKBU4PaDOKkTH8V15WuA1BlRRl8PWf0yMQG8IrDbeOz8BBK6SHovgdcUg4+VNiZkkzDJFL2eTENJmUMbeg7ZzMmvQo7FFUvPqCsoIUMLuWh70PS7Gxk5So5Fi3gwsxckLOx4Zc+BwXI7N1MOsy0tfGiSLiA2UFKTBun469euyjo6t5+0FFbJxoYlocWBP59lmil791h2HeRGSgrCAFw75VEe/DU5p18/SraENMl98nvyQ01W+2HxETKCtIAXDl8KdHN+L7zvQlIuDA6sjPn6S9poriZHlQVhCh+WdFeHyMrO9MPyIaDq6LfPc2+ce5/kQcmJpDixg4J7e8j40Wl6YA3w4q7F7U6s+Zr4k4QFlBhCMxhn0aEt9fZIEGnraDvJg05vjmd0QEoKwgwvH3stclAu2IWPl+nM/T4HgiAlBWEIG4dSpOJmWa9vAgYsXaXuLkbvH3orfE1EFZQQTi1tlo3zK2RNx829c7OiqVmDooK4gQJHyWS5PlLfsIaqrs2rVr+vTpRHsmTJhw4MABogcc3CWW1pLjW0w8woKyggjBud3vrW2F/l3rgwcPSL7I94Z5wbuYddjTJGLSoKwgQvAhLNXNy5Loh1evXoF90aRJk8aNG48ePTo4OBgSBwwYcPjw4X///bdq1aqPHj2ClJ07dw4bNqx+/frNmjWbOHFiWFgYv/mOHTsg5dy5c9WrV1+yZAnkj4iImD17NuQkeiCgjpM0xcQHi6GsIEKQkiz3Ka2XQfpSqRQURCKRrFy5cu3atWZmZqNGjUpJSVm/fn1AQECrVq1u3rxZpkwZ0JrFixdXqlQJhGPmzJmfPn2aMmUKX4KFhUViYuLu3btnzZrVuXPny5cvQ+LUqVNBaIge8CljRQj7KVJOTBecbwURApYhXsWtiR54/fo1aES3bt1AO+DrggULbt++nZaWppatQoUKEGrx8fEB3YGvMpkM1Cc2NtbR0ZGiKJChXr16VatWDValpuo9pErR1JvHiS6FHYiJgrKCCAJLPPQzvxEohbOz84wZM1q2bFmlShWwR8CLyZoNzBnwepYuXXrv3j2wTfhE0COQFX65fPnyRChomon9JCWmCzpBiBBwEx1JiD6wtLTcsGFDnTp1tm/f3q9fv3bt2h05ciRrtvPnz0PYpVy5cpD5xo0bq1atUssArhARDG5SKWLCoKwgQkDRbMw7fUUT/Pz8Ro4cCQHaZcuWlShRYtq0aXyMVpV9+/YFBgYOHTq0VKlS4PXExxfkaFdGRmwdTNlRQFlBhAAez5Ev9dKrCt1ABw8ehAUrK6u6desuXLgQoicPHz5UywZhFHd3d+XXM2fOkIKDkTOFS5ryLDMoK4gQWFpJ3jxKJHoA9AJ6cFasWPH27VsI3/75558Qr4UIC6wqWrQoRFLA5YEYChgpV69ehV4hWLtt2zZ+28jIyKwFglcFAqTMTHTNxzdShiVefqY80y3KCiIETm7mUa+TiR4ABZk0adLRo0fbt2/fsWPHO3furFu3zt+fm9mkQ4cO4O+A4/P06dMhQ4bUrl0bwiu1atWKioqCPmaIs/z000/Hjh3LWmbfvn1BjMaMGZOcrPtjvnM+xtJaP3EmgwGncUKEIPxZ8t7VYcOXlySi5/dpr9y8LNoO8iKmC1oriBB4l7CWmNFn//lARE9SvKxNX1PWFILjVhDBKFfN4WlwQoPvCuWUYfz48deuXct2FcQ4+GFsWZkxY4aeRtkDOZUsl8vBzM/pkE6dOpXTqr0rw53cLGhTf4MQOkGIcKz5+XlgPefarbN/GVB0dHROI1whHSKp2a5ycXGBPiCiHyIiInJapeGQvLxyNEZWjX7Wd3JxG1cTf3kQWiuIcDT8zvPMP1E5yYqrqysxMDQIRD74a/Ybj6LWJq8pBGMriJCUqW7r5mW5ZZ5YZopW5eK+6NQk+XejRPEqMpQVRFA6jyqSJmP/WRFGxMSzO0mhVz4PmF+MiAOMrSAFwJ6VEbIkpuv4IkQE3Dj2+ebZ6MELixPRgLKCFAxb5r4Bs6XPDBN/19++VRFRb5IHLxKRphCUFaQAObwh8vWjJJ/S1m0GmOA4jmtHY26ejnZwsfhhkg8RGSgrSEGS+InZsfwNxDJdClt+066Qdwl9TUwpGKnJ5OTWqLBnidCwghq61GjuTMQHygpS8Ly4l3xx34eEzzKJhLKypW0dzGwdzSUSRir9UjlpmrCKWeZ4KJpQFMXIWeVXyMIyDJ+NsOkVm+ImkCK0RJGT759g+NIoWAeJig0plvmyljaDr7AjllZMiqJcoKAkxR7hK8NwhUvMiDyNmFnCdyohVpYQk5aYkMbIiZUNXbaqU532LkSsoKwgBsTdS/Gv7iXExcikqSwjZ2SpXyonpRjtoayt8BX+GObLV0VNpjiZYHllUaYT0BCGVeSHTJxM0FxpUPcZSlksl5P7j5JIuGL5FG4Ny+UBoaHo9Ax8ObB/mtMxytwclIgG5bJxMPMuZvW/tgY3+kZ4UFYQEXHo0KHbt2/n7+VBSN7BUbaIiNDw2yJEh+AlRkQEyoow4CVGRATKijDgJUZEhEwmM4cQK6JnUFYQEYHWijDgJUZEBMqKMOAvmBERIZfLUVYEAGUFEREQW0FZEQC8xIiIQCdIGPASIyICZUUY8BIjIgJlRRjwEiMiAmVFGPASIyICh8MJA8oKIiLQWhEGvMSIiEBZEQa8xIiIQFkRBrzEiIjA2IowoKwgIgKtFWHAS4yICJQVYcBLjIgIlBVhwEuMiAiUFWHAS4yICJAVDNkKAMoKIiLQWhEGvMSIiHB1dZVIJATRMygriIiIiYmRSqUE0TMoK4iIAA8I/CCC6BmUFUREoKwIA8oKIiJQVoQBZQURESgrwoCygogIlBVhQFlBRATKijCgrCAiAmVFGFBWEBGBsiIMKCuIiEBZEQaUFUREoKwIA8oKIiJQVoQBZQURESgrwoCygogIlBVhQFlBRATKijCgrCAiAmVFGFBWEBGBsiIMFMuyBEFMmlatWkVGRkJVpyiKT4FlHx+fAwcOEEQP0ARBTJ02bdrQNC2RSOgMwGxp27YtQfQDygpi+vTo0QNsE9WUokWLtm/fniD6AWUFMX3s7OxARFTn3G/QoIGzszNB9APKCiIKunTp4uXlxS/DQqdOnQiiN1BWEFFgYWEBymJpaQnLtWrVKly4MEH0BvYEIV/FjWOfP71PlabKlSk0TVioVwxLwQIDVYxw3ylFTUtfJl8qnSJFuUBLKEauUiHhqccoVvJFQYKEMF92xaVzm1Ppa79slzkbj8SMunbtukyWVrFiRVsb2y8lEK4QtXYgMaPlaQycC6NSMk1TDGRl0k+TUVmgJISVq+ZU2VBxwspT+HKVMh+52r7MzWlbJ4vazVwk1sToQFlB8snZHdGPb8fSZhS0YVnKl1rEtR+oVCyVLhmKT+5bxvIXKSGZl4l641QTHUXhLMtQmTLwq9RqsYSQLLJCSWBbrunSVKYS0svOXAJlRtg0oqYFX05NReky1DM9nSuJgl2obqg45wyJVCmKUxU2Yyu1fUnMKRCa1BTGxcOy289FiFGBsoLkh9unYm+eimnyg5dbEQuC6JN9q8Ks7KjOI7yJ8YCygmjN9aOxwZdiuo3zI4ggHPotDCyXrmONxmbBkC2iNaGXY0pUciSIULQZWOTTu1RiPKCsIFqTKpUH1MZBH4JibkH/dziGGAn4U0NEO+RSwqQx1vYEERJ5GpucYDQ/kkRZQbRG2XmBCAbDsHK50YRBUVYQxAhgs3aiGzAoK4iWoKVSEFCUMV15lBVES3BAQoGBThCCIDrGaMwVlBVEOygKDZYCAGMriCnD/0AOQTSAsoJoCWpKQUDT3O8wjQWUFURL0AMqCFiGJQyGbBEE0SEUxWLIFkEQHYIhW8SkkSgmZEKExbhiK/gLZkRL5ESAnwTt2bujUZPqxOAR7DgZJvO8eYYNygqCaMe+/bvmL5zOL5crG/BDj/4EyQw6QQiiHY8fP1Auly0bAH8EyQzKCiIEe/ftvHr14sOH9ywsLStVDOrXb6i3FzeFIsuye/b+ffz44bdhr319ilWtWrNvn8ESSaYoglwuHz9heNS7yNWrNjk6aJqVbt1vv5w4+W9MzKeWLdp+U6fBxMkjd+865urqBguwdv7cFXw22N2CRTP+PXTBxsYmLS3t9z/WXL126f37qICAwPZtO9esWYfP9ubNqz83rQsOuQUHWb58xa6de1aoEDhy9ICQkNuw9sSJf39btzU0NHjN2mWnT17nN9m8ZePxE4c/fnzv7u4ZWKnKqJETaZpzCNp1aNyn96DY2M9/bV5vbW1drWqtYUPHwoEREwWdIERLtK8y0PZWrlpcvnylWbOWTBg/E5r93HlT+FV79+7Yuu2PTh2/37H9cJs2Hf89sn/Hzs1qmy9aMuvJk4eLFq7SrCmH/923e8/2kSMmHNh/ply5CitXL4FE1TcZZsuvKxfBVu3bddm+7VC9uo2mzxx3/sJpSJdKpaAgIHALF6xcunitmcRs8pRRKSkpK5atB/OkadNWZ0/fLFWyjGpRoEH7D+waPHDk7n+O9+s75Nz5k//s3savMjc337lzM0jM/n2n//pzT+i94E1//Ua0gXvxCA6HQ0wW7buBoJH/+fuuIkV8+EaeJpNNmjIqNi4WZCLk7u3Spcs1a9Ya0lu3al+5crXkpCTVbeH5f/bsiWVL1nkVzmXq+aPHDoKFUvebhrDcqmW7Bw9CIyLCNG+SmpoKxsX33Xp/26YjfAUb5969kM1bNoC+vH37GuSvY4duvHZMn7YADhVMm5yKik+I/3vHX4MHjapTpz58rV+v8YsXT7du+71D+66gKZDi7V20R/e+XFY7e7BWQCiJNnDv+sCQLWKyaC8r8MyHFj5x0ojW39Zr0KgqaAokfo75BJ8BAZVu3bq2aPGsY8cPgdCAZ1SiRCnCDf7iOHX6GJgAkybOhmy57uXZs8egUMqvoGVE4WRp2ATaNlgl0MiVKeC5vHjxDI4ERNDJyRl8JTCmQGvA0KgcWNXOzi6nokCGZDKZapylVKmyCQkJ4eFvrbgUFQAAEABJREFUlV+Vq+ztHRITE4g2cC8eonGULYJkcPny+SnTxnT/vs/AASOKFy9589a1ceOH8avA/bGxsb185fzCRTPBlqlfv8nAH39ycysEcgAhlQWKDhcrS6tcd5GYmAgCYW1to0yxssr9bYAJCfHwOXxEP7X0mE/Rfn7+vyzfAE4ZuEgQfPHyKtK754AmTVrmVNSnTx/VDpU/mOTkdOOLor6qW55hCcXgKFsEyeDwkX0Q7Ozfbyj/lW/MPGAFgO8Df69evbh9+/qmzevhMT5vznJ+7ZjRk8H1AJMBfChnZxcNu4DgK9hEqakpyhRle86KPONFqq5uhfi9gIeimgECrvDp4+M3eNBICLXCgYGHNW/BNF8/f7V4ihJbW86QSU5JVqYkJSXCp4uLycZlNYBOEKIl3CuWtbPG4+JiC7m5K79evHhGuQydMi9fPocFsA46dOgKsQzwZdL3Q9Mtmn87Yvh4G2sbZYg3J8AW8PT0Uu36vRt6R7lsYW7BN3IecFj4hSLePvzL3sHB4f/8fP2hQwpECrqBQEoIZ/VY1a5dd8b0hWBMaQiIFC9eCnTt/v0QZQp0e9nb2Rcq5E50AYRsKeNprCgriJaw/GuLtaBE8VI3bl69E3wTQp7KzhHoMIbP02eOTZvx85UrFyCccfXqpYuXzgSUzxRGge7YGTMWQS/vrn+2at4LREnPnD0B/ThJSUnQn339+hXlKgh5PHp0H4ImsAwu2KXL5/h0kI/evQZCjBb6qsCHgm3Hjhuy4pcFRCGFEPFZu25FWPhbkKFt2/+Eg+ePDUwbkIzbd27EKMJDPA72Dk0at4RADJxLXHwcdD/v27+zU6fufAfz1wMhW7XX1xsy6AQhWqJ93LBv3yFgLEyZOjo5ORl6RqCPOTIyfMLEnyZPmjNm9JRVq5dMnjqacP6CK3hD33XqobY5+B09f/hxw8ZVVavU9PcvkdNeenTvFx398ZdfF0Jrh2zQ7bJ6zTJ+Vbu2ncH6GDCoO8RrGjZo2uP7vuBY8dHcrl16gqGxfccm8HTAkSlfruKYMZxlBEHi0aMmQTcwL2dVq9RYtnQdmFSw3KZVBzBbfh43FPqeVQ9g6JAxICKz504CAYJYzPfd+nTr2ouIEnwHM6IdcilZM/5Z7xkliGFz9tzJWbMn7ttzEjp0iPGzZc7zUoH2jbvrxqXSN2itIFrCOUD4KBIaePobkQGAsoJoh2JWhILp6Zw4eeS90OBsV7Vs2Q56bYjponhPEI5bQUyUAnxR6tjRU6QyabarbFRGrPA0qN8E/ojp8JUDXwQFZQXRkoJ7ZJrwb/NyBWKgLA6HQxBEtKCsIFpCY8S2AMB3MCMmDYOvCioAcIpsxKRBTSkgWHy1O2KyoAdUQFD4niDEVKGMqHabEBhbQUyZt2/D0F4RHoytIKZGTEzM9QwsJNb1i80jCJIzKCtI9kilUhCRGzduXLt2LTo6urqC/v37u7sWXjP+GUGQnEFZQTJx584dkBIQlAcPHvBSMmfOnBIlVH6vLDem+YRMBgsrCfwRIwFlBSFPnjzhpQQICAioVq3a8OHDK1XKYVZqCTEzk0Q+kxYuYUEQoZCnMYX9cp/T10BAWREp4eHhSilxd3cHKenSpcuSJUv4t09oxt7FLPjCh8IlvAkiCI+uxVMUVaqqLTEScBonEREbG8vrCAgK3HeQEt7NcXJyIlry27gXVVsULhWU++z2yNezbd7LWi3cKtW3J0YCyoqJk5aWppSSd+/eKaXE2/trbY31k17aOpgXLW3rWMiSkadpyElxM4Wwyi/cv0y1jsqx75RS5KSorFMYcSVS2RVBU9zLLzTD56YITSgma/1X3Z1iGSwF9WaS9ZBoimIyD4TNnCdjn4rDZnMoRHUPZpQsmby6H/8xPKXbz75OhYznnYYoK6ZKSEgILyV3797ldQQEpXTp0kSn7FkZ+SkqRS5j02R5nb5ZoQZ5Htf1pS3mWmx6oRRNsbnJCq9U6RuwOexUpdxsZEXD0eb0VVneF1nRmB/Og2JkabEvY/d+THkFxwBPiMTExCNHjhCDB2XFdHj+/Dl0BvMRkzJlyvBSEhQURJAMDh8+fPPmzRkzZhDDZvr06cePH4c+fv4rTdMMw/Dqdvv2bWLwYMjWuImKilIOVHNxcQEp6dChw4IFC/jX3yBqwAM/15e9GwIzZ85MTk4+e/as8qkPymIsmkJQVoyR+Ph4pZTIZLIaNWrUqVNn9OjRICsE0YixyAqwaNGi7t27P378WJkCygJaY21tBGFylBXjAGxg5ZhX6BvmwyU9evQoWrQoQfIMqHBeetANhGXLlg0cODAsLIz/2q9fv7Fjx65evTouLs7BwYEYMCgrBk1oaCgvJXfu3OGlZMqUKRA3IUi+MCJrBfDw8IDbPW3atPfv30NgZdCgQXw6hId27949efLkr+/O0xMoKwbHixcvlAPVSpQoAVIyYMCAKlWqEOSrMS5ZAapWrdqzZ89169ap+j4NGza0s7ODCD3IyoULF+rWrUsMDOwJMgjevXunlBKwb6EHByIm8GkUjrQRsWHDBnAnwbMgpsKOHTtWrlx58uRJqCqG88oPlJUCIzExUTlQDUJxyoFqbm7ifW2Fvlm7dq2FhQUEKYgJkZqaCloJvdEQ5QXD1tfXlxQ06AQJjVJKXr9+zUtJ165dDaEqiAFwgmxtjeaXNXmEH0wA1gp4Q9u3b584cSIE9Qs27IKyIgT379/npQTgpWTcuHHly5cniLAYXWxFK5opIIrfkf7444/Lly/X+bjqPIKyoi/AGFGOefXz8wMp6d2795o1awhScJi2rCiByrZp06bIyEiiCL588803AhsvKCu65OPHj8qBajY2NnB3W7ZsOWPGDNMzvI0UkcgK4K6AKHqphwwZAs4R+EqCnTvKytcC0VallMTHx/M9OHAj+ZuKGBQymUwksqKkgQI4cegiGDp06PDhw6GKEj2DspJPbt68yQ9Ue/78Od+D06lTp2LFihHEgBGPtaKGubm5o6PjlClT4OEHsgLBPqirYFAT/YCyogUPHz7kpQQ+g4KCQErGjh0bEBBAECNBtLLCU0YBUVyH5s2bQ0xXT8MsUVZy4c2bN8qBakWKFAEp6dmz58qVK2ka54k2PkQuK0oqVap04cIF6FWAZRCXmjVr1qpVi+gOvMTZEB0drZQSCwsLiJVAvx0YkPb2RjPrH5ItKCuq8KOlmjZtum7duooVK8KTUlejuvESp5OamqocqBYTE8OPLhkwYICnpydBTAXj+gWzMJQvXx6sb4ZhIKZbp06diRMntmrVinwdYpeV27dv81Ly+PFjXkrmzp1bvHhxgpgiaK3kBJgqYIyfPn36/Pnz8PXy5csuLi5ly5Yl+UKMlxgUhJcS+ATbD6Tkp59+yvG1OIgJgbKiGUtLS/CJYMHb23vq1KmDBw+uXbs20R6xXOLw8HDlmFfwa/hf4kCwSiIxpgnNka8EZSWP+Pn5bdmyBYKMsDxmzBjo9+zevXveNzflS/z582flQDWw8UBKGjZsOGHCBOjAJ4gowdiKVri6usIndFZs2rQpOTkZrl5SUlJeoo2mJitw5kop+fDhAz/mtW/fvl5eXgQRPWit5ANnZ+dRo0YRxcyn/fv379ChAzQozZuYyCV++PDhxYsXQUru37/Pj3mdNWtWyZIlCYKogLLyNdja2h4+fDg0NJQoXo0CAYQWLVpkm9MULnFISMjSpUuhb2zYsGGBgYEEQXIAQgYoK19JhQoV4LNWrVrw5C5WrFi2MyubwiV+//49BK4HDBhAEEQjr1+/BjeZIF8NhF1++eWXnNaawgh0eP6AcUsQJDewquiQyMjIiIiIbFehrCAiAquKDjl06BBEWLJdZQpOENYVJI9gVdEh0Lua0wT7KCuIiMCqokNat26d0yp0ghARgVVFh2BsBUE4sKroEIytIAgHVhUdgrEVBOHAqqJDMLaCIBxYVXQIxlYQhAOrig7B2AqCcGBV0SEYW0EQDqwqOgRjKwjCgVVFh5h4bMXc3Bx/lorkBawqOgRjKwjCgVVFh2BsBUE4sKroEA2xFSonvTF8Ro4cef78eYqi+K/KhVu3bhEEUaFx48afP3+Wy+V8JYFPhmE8PT2PHj1KkPwCsRVQj2xniTbi2MqKFSt8fX3pDCgFRYsWffv2LUEQFZo2bQo6IpFIVKtKvXr1CPIVaIitGHfI9n//+5+qtQXLNWvWBGUhCKJC165d+fcNK4FK0q1bN4J8BWCnFC5cONtVxi0r3bt39/PzU36FutK5c2eCIJnx8fFp0KCBakqNGjXUhAbRFoittGnTJttVxi0roJeNGjXi30wIVm7lypX9/f0JgmQBbBNl3YBq07FjR4J8HaY8bgWqCzyLiMJU+e677wiCZEehQoWaNWvGP4EqVqxYunRpgnwdXztu5dUDaUpiimoKRL0YlaAGhNdZ7p9imVL0LlGsIulLBpK+PnOSaipE6dW6pUD0mC+7JAwUqyg4UzlmTWr0Op14umzJsnRikUc34rhy+CxqfVxU1iNgVY88c2ZFKXA8qseQ+UxVM0NWmlAMyb5bTSIxLxlkTYyHT2Hy9++SwQLMlAqXHi5HpnukvOvc/zNuveo9Va7PfN/4dEW3TKYCs95fPpmiWZZRflFukildfRuVw1BUniql2lQv8y4pJblelW5cPclhky+HoFYhFV+zryyqR02zhKEyH7x6f2t2NTGbbOk1KttdZsbaxtK3vCURFg3jVnLpYN69IvxjRCqcWJpUrYapnyqrIhQcmVtjNhkUt4wiGlHfhmR7iblyqMx5SPY3P1O6sihWUStyIg83NdeMZhY0y7A2Dma9pvoSw+b03x+fh8bLZXC8LCvP5cwVjw7FZc3p5DVevay3V2s0lK9h1dfsOLdts6lN2TSWjOumMVvekZhDe2PdClt/N8ogXgqsSVZ2LA5nWKZmK49CRSwI8pVIyZl/oiJfJw1aaLjRn9tn4oIvxFSo7VKmhj1BjIoPYdJr/76H52vXn4sQQdAwbiVHWdk85w0todsOEegQRcKzO8nXj0UOXGCIynJy24eXoQndJhYjiNFyYE04K5f/MMWH6J/169fDZ7ZvE80+ZPskODk5QYaaonNKVLa2tjfbvyaSGB7PQ+O+6eBJEGOm7RDvxIS0Z7eSif7RMG4l+5Dt/SuxtnZCR4BEgpevzZunCcTAeHQzmbB0kdLGFFdGssXWzvzef59LVNH7rdR6vpWkeCmRMATRA5a2tDRFTgyM2A8p+Q8YIgYFzSQmSon+0XrcCvT7yKQoK3pBTuRpMoNrwHLGEI8KyQdwH9OkQtxKE59vxcjghj58bb8qghQ42s+3QmHF1xsU0TRMBkGMBO3nsmXRz9YbDEWxKNqI0WPic9kaGSgpiEmgdWyFQvdfb1CcIWhwtiBN0RTecZOAIgI1Xq1jK6wh1nwTgeV/zmZgMCxjtLOPIplghYrdmfh7gowLfsZDgiBGDiUK7ZIAABAASURBVMZWDAhWAUEQIwfHrRgWlOF1MHO/5sdub5NAIqFoQawFrWMrcFhYxfSJwTlB3Awg2O1tEnBBMkFGyOcjtkLhgDg9QRnku5kUNxsfJaYAyxBh6pfWsRUGOgYYI6hkc+dNGT6iHxGQPXt3NGpSnXwFrC4mRdM5GTNHGjqH/93XoFFVnb+Z8MWLZ1Ds3bt3YHn6jHFjxg7Omien9HzTp1/nFb8sILqoVAUCxlYMCMogYysix8nJuecP/d3dNU03U7duI5lML78MLlc24Ice/YmxYeLvYDYuuHErGMUwMFxcXPv0HqQ5T6OGzYh+KFs2AP6IsaEhtpLDKFta6xE1b968+nPTuuCQWyBg5ctX7Nq5Z4UKgZAO9urvf6y5eu3S+/dRAQGB7dt2rlmzDr/Jy5fPDx7affvOjaioCD9f/5Yt27X9thNRWKT9fuw6f+6KJcvmwGNk4/q/IfG//y7+snLhhw/vSxQv1a5d5xbNv+ULMTczDw6+NXf+lM+fY2DV8OHjymm8Qx06NW377Xe9ev4Iy7Gxn9t1aFy/XuPp0xbwazt1bt6xQ7duXXvdv3/3r83rHz267+jkXKvmN716DrC1tU2/OBQVERn+xx9rrl2/7Obm3q1Lr6ZNW5E8A1ErmjYFayU+IR7u+LWrl2I+fypdqlzjxi1atWzHrzp2/NDBQ3tevnxWrFiJhg2awiXlh+okJCT8s3vr9Rv/vXr13NXFrXbten37DLaysoJVbds36tmj/4VLZ8ATObD/jIO9A9Sopcvnwlevwt7ffNMQclpYpM+pHB39cfbcSXCPihTx6dqlp3K/2TJ7zqSYmE/Llq7jv/bq0wmqyoF9p5VrE5MSB/QfDlXul+UbKlasrLot7GjQkB/Kla0wY/rCGTPHJyTEL12y9snTRwMH9Zg5YxHUEKirrq5uDeo3HTpkNL/Jp0/Ra9Yuu3c/JCUlpVq1WnBSRYv68qtevXqxYOH0129eBgZW7alinoATBJucPnmd5NwoDBCt38FMEe2GbEml0pGjB0gkkoULVi5dvNZMYjZ5yii4rLDq15WLdu/Z3r5dl+3bDtWr22j6zHHnL6Tf0dVrlt648d+In8YvmP8rXL5ffl149dplSDc3N4fPzVs3dun8w5jRU4hCU6ZOH9uv71DIWadOg0WLZ506fYwv5N37KLgNkybOhlVSmXTxklmaA6JVq9Z88DCUX4ab5+HhGXovmP8aHhEG1QgyhIW/HTtuSEpqyqqVf86eueTFi6ejRg9Q9efnL5jWpEmrWTOXBJSvNH/h9LdvX5M8w8XpGYOzVvIxRG/RopkP7t8dOXLipj92w8N2+Yr50M4hHW7NwkUzS5Uss33rwf79hsLdX7VmKb/J3n07tv+9CW7rvLkrBg4cce78SWiZ/Cq46YeP7CtRovTiRattrG2ioiKHDe9TISAQmnGXLj1PnzkGFYnPaWZm9uuqReA1gFKUKVMewhPv3kVpOM6goOoPH92Ty7mps0Bf3r3jZvwMC3vDr4W7X7VKjWw3TE5OHjdhGMjf5ElzVC8PVG/43Lr19zmzlx0/emXokDEHDv7z75H9kAh7GTVmIDxcR42c9MfGnc5OLkOG9oJ6BatkMtn4icMLFfKAyzXwx5927NwMlS3rTnNqFHmH620RpH5pHVtRhGxJ3oF2BTcMHkpQmeArPPxD7t6Gdpiamnr8xOHvu/X+tg33ErmWLdreuxeyecsG0Bf4OnXq/KSkxMKenNpVDqx67NjB6zeu1KzxP/4WVqta87tO3fny4alY95uGTRq34NMTExNgQ37Vhw/v1q3dYm/HzRTfoX3XJUvnxMXFOjo65XSoQZWrrVy1GKQH9hIScqt+vSb7D+yCG+/tVSQ09A4YRyVLlN7013owgkBQ+HLGjpnarXubS5fPgV1DFFUHdlSjem1YhmYAT+bTZ4737jWAGDP5GKIHtxgsBbgdsDzgx+H16jV2dOAu15Ej++GZP3LEBFh2dnbp02vQoiWzenzfF5Y7f9cDbr2vb/os3FAZ4I4PHPATUeiag4Pj8KFj+VUgRpZWVuCYwLMKbhnYKY8fP+BXQb36tk0n/vpDNOTUqaOgGvB4yOk4q1apCU+4Fy+fwZ2FBu/vX9LO1g4OHiwdEC+wf6sE1ch69nCXp04bk5SYuHbNZqWVpAoYUHzVbVC/yanTR0+fPgZGU2hoMGdkLVkLxwyrBg8aefnK+T17tv80fNyFi2fev3/3y/KN/KFCynddWmQtNqdGQfIMnIowPUF6j63AHYIGuWDRjCaNWwZWqhIQUAmuCKTDVQZDplrVWsqcsPbosYOx0PIdHOHs9+7dAa6E8mlfuLC3MmepkmX5BYZhnr942rjxl3swaOAI5XLx4qV4TQH4ag11yNExx0OFOpSUlASmpr9/CXhS9e09+NHj+/dCgxWyElwliAvI378fAo9BpTZ5ehb28ipyN/QOLytAjerptxl2XcyveGRUOMk7BukA5eMXBeDk7vpnKziSlSoGgbVfuhR3v+Bmgf3f84cfldkqV64GiXD1QFDAJLlx8z9wBJ49f8Jbf6A1ypzgSSmXwUIsWbIM/xJCoHmzNvCnXAt75BecHJ3hMzUlRcNxQjP2UtxckBW442BgWltbg2EFKnD37m1wYYoVKw6+TOZLQYEUQsVYu3ozVOxsi4XSlMveXkVBWYjC9oFz5DWFLwoqPEgYLIeHvwV3D+oSvwr26+7ukU25GhuFQaF9bIXS7lVIlpaW4JeCHQgPGYikwF3s3XNAkyYtwReFtVn7gGM+RUODnDBpBITWf+w/DFxN+KqWzcIyfY5ukAmol5aWVtnuGkzizIedC4UKuYOvC1Uf7iuIC1R6eNZBbWjWrDVUfXj8Ei4EEP/o8QPocVQ7ZuWyjY2NctnK2hrsI5J3DHNEkPY/KRg/bsbBg7vPnD0O4gLP//btu4CagFiAtQ91AP5UM4MxC5/rN6wEWwbcH3jSQGvf+PvqI0cPKPOoGgVgkObUnonKTc+jFkI7h0dFh/ZdwD4FCwjqEjgXkA53vHKGBCiB68Db2lAnc6p1gJWVtcqyFRwwUdQcOH21msOfCFQSa2sb1fSshUM919wo8oJEQlG0EFVMQ2wlJ1lhKS3H//r4+IHJB/fs9u3rYI/MWzDN18/f1a0QrBozerK3d1HVzGC7QtwLAqJLFq/hDQSiuCWF3NyzlgyaRdM0f9t0AuwRwitws8FgAYGoUKHy2nXL4akL/jZEZyGDi6sbPIrVugZ4U4gHlI4PNAKcyarN84QLhxveL7HyMW4Foqo9uvft/n0f8GUuXjq7Zevvdnb24ObAJW3apFVdhZ+rxKtwEaiChw7v6dTx+9at2vOJ/FMnW2xt7RIz/Nyvp0qVGr/99gvcYrBKgipXByMoIiIMvsLj5PuuvbPd+4xpCyFgDIYVeDTZipfqwSvqA6cy8KwCU2junOWqOSU0Z3OBi5ecnKSanpTlBPPeKDQgl7O0IF4QxFaIVu8J0vagwJ8EKSEK2a5duy6EzeF58uTJwyLePpYKowN8Iv4Pgtu+PsWg5sFNhXTlJYMgOfxlWzhUgtKlyykDq8CGjatWr1lG8gvE8O6G3IYuhkqVqsBXiAvC8YOLDsoIHY2QUty/JPRbgaWtPGyIvcFaZQlPnz7iF8Cfev36JdjAJM+wDGEMcPZxLV2gxMTEvft2QnOCJgcSPGTwKLhKTxSXBdxS6CRSXjpwOiDqCQY/PMYhCOqWccfBO77y34Wcyoc7DvaFMkwO0auxPw/hw675AA4j6l0kFFK8eEmoe1AnoXy443DfqypiQ2pABQgMrDJz+iKoddu2/5ltmRCmUS4/e/bYv1gJ/tzhHOGpqTx9D4/CJRTukqdHYS7Ek+FtPXv25OPHD2pl5r1RaICbOUcQa0XDe4JykBWGsNpUfTDwoHdm7boV0IcCPiHcCagQUJ/gFvbuNRBitHyQBfqAoIeFH1kI+gLSs3PXlrj4OLi7EEaF4F/Uu+zfy9W2TScIj0PmO8E3Dxzc/feOv8AfJvmlcmA12NF//12AIyQKjwb8ZOikqJLRI9CpU3cwR6H/AuoBnM5v63/t278LxPz4tXDYEEKGY+b6zv9cA5/Qh0qMHS2fb6D10IkzY9Z4MFWgS/XEiX+fPnsEAg2rfuw37PLlc+DdwDWE+z5r9sTRYwfB3QcfB6QZHj/hCksBgheQPz4+DhQqa/kQ+IBNli2fd/PWNTCFNmxcCZavMtSiLRAmg84ECJ3ydxyABbjjYK6CfZHTVrAWnJFNf/32JOMpogoEia5dvwILEMuHasnH/sDKqF699pIls6FzCs5x/4F/Bg3+4ZjiiQu96XAFliybA5UKBGXWnIlgv6iVqVWjyAlu5hxBhshDbKVNmzbZrtJNyBZitKNHTYIbAG424WLvNaDzz8+PeyUoRCtAwrfv2ATOEdiW5ctVHDOG6zMG1xr67aBqtm3XEFykyRNnR3/6OHXa2F59Os2drW6JQOAjLj4WMkMVhHoA/Q7QqUTyi52dHTyswNpUhtbKl6+4b/8u5Vcw73/fuHPHjr8GDu4BdxfCtz+Pncp3csnlaTY2tmDqQ4c6xAug5k2ZPBci1nnfu2LyLqMftwJm6awZi1euXsw7/6DygwaO5AcTgfGyft02eLSAHKekJMMdh45Y3midOnkedKD27tMJNh8yeDSED65fv9K+Y+O/Nu1RKx8uKfSwQvsEGYJtmzVt3b//MPIVQAwFmis4vPxXuOMQB4S+S81bwY2GI5wxYxzUB7VV4D39/vvqCRN/Ag+9Q4euyrEz8+euOHhoD6jGgwehEMUDuYG1RFHroFt9/fpfW39bD05/wI8/8VFeVTQ0ir/+3E0MDK3fwfzX7FdgqHca6UcQXXPr9Md7l2KHLcu/taUPrvz78fbp2F7TDeuoDBN+uGbWsXMGwu4Vr2ia9JrqR/SMhncw5zTKFucv0xtCjVbSCpyyDtEW7eey5dwzYqSAPz9p8sic1m7dsl/DYDkh4EYrGZwTZOxT1rX5tn5Oq8aPn1Hnf/WJaIB+RlqQkG2+fhNEjBXOt1+/Pae1Bawp6aBhoGM03HHoxSM6BQJqZ0/fJIYK19UoyJhLrcetaNsTZGjwY58R8YB3XHg0jFvR8AtmfKKKCIrFN1maCDQ3l60QtzIfsRVD9P9NA8OcGIGlcZpRE4Gb1xHfEyQ2DHNiBIJPEZNBqDup9Vy2lEF2giIIYjhoPd+KYFM2IAhipGgdW0FrRX/ApaUNz/XE4XCItmgdW0FrRX/ApTXAXzDjG1wRbcF3MCMIomPwPUEIgugYrWMrZhYSNIn1hJkZbWZBDA1aIjHAo0LygYUVTUsK+DdB2TtBdg4SuQx1RS8kxsotLPI5HZH+cPOwIjiu2iRIk7LWtkJUMK1jK0H13ZIT8jnBH6KZyBfJ7r7WxMAoUdkauoJe3EkmiJGTkigPqudK9I+G2Er2slK0rIW9i/n+VW/O7nERAAAQAElEQVQJolPunIqVpchb9/MghkfZGo7XT0YRxJg5tDrMztncp5wl0T8a5rKlNPQr7l8bEROVVuEb59LV7AnydXx8Lb124kN8jPTHucWIofI8NPnUtnclAx2qtdDxZAKIvnl8M+7uhRjXwpZtB3mSgobSPFzh0PqoiJdJEGdh5NmPtWAz5g5huJ89ayqK5UbY5R6vyWO2vOwxAy3eecTmeSoUVptJU2gziqZoR1fzbuO1mKO/QLhxIu7uxejUFIaVE81zeeXlTmm+SsoSWO1noFG8lpIl2u+XYeFesBoOJu/7Ytkvo0ZV95jz3rOpihn7VV+V7fHkVDJtRkvMaK9iNm0GCGcIaz2XrRrJyUSaU6iFP8vMl+XLouq1UubMukq1PEoxEi/rWor/8X6WFEXO4cOHT5061d1d8SYEmpMcorqfLNuy3LwPme6aejZFsVTW481ISj9OZYqGM1XMU29nbI//hA/qr89QvydURt3PtgapXEDuamfEgzMVovyS5Yqpl5RdffiySZa1mTZRWXvhwoXQu3eHDh+WzYaZ72O2x6l+mDnc9Fzqf+ajpQjJtr5nf4JZW4ECCzuJteDxOq3nslUDjtja2uA6L1T5GPfKsZAE/giiI+xM8WLKJbGMebyjG9YTHaD3dzAXOGlpaapvTUWQbMF6okNMf74VmUxmbm5OEEQjWE90iOn/JgifQkhewHqiQ0z/N0FQXfAphOQKWis6xPRjK3K5nDbAWUwQA4NhGKwnusLEYyuMYv4SrC5IrqATpENMPLaCdQXJI1hVdIiJx1awriB5BKuKDjHx2ArG4ZA8glVFh5h4bAUfQUgewaqiQzC2giAcWFV0CMZWEIQDq4oOwdgKgnDgsEkdgrEVBOHAqqJDMLaCIBxYVXQIxlYQhAOrig4x8dgKOsxIHoEwHMqKrsDYCoJwYFXRIRhbQRAOrCo6BGMrCMKBVUWHmP64FawrSF7AIU46BGMrCMKBVUWHmHhspWjRoi9evFi4cOH58+dTU1MJguSAv7+/paUQLxI1ecDu+/nnn9+8eZPt2jy9fszwAeG8dOnS1atXr127VqZMmRo1atSsWbNChQoEQVTo1KnTkiVL/Pz8CJJfTpw4Ae2LoqgHDx5AK8s2j4nIiiohISFXFTx//rymArgK3t7eBBE9Xbt2nTNnTokSJQiSLyZPngyKMXv2bIlE0yvcTFBWlCQlJfH2CwBfeX2BT2vh3yuJGAY9evSYMmUK2LMEyTNyuXzDhg0ODg7ff//958+fnZycct3ElMNXNjY2DRXAclhYGEjMkSNHpk2bVqpUqRoKKlWqRBAxAfFaiNoSJG+8e/fOw8Pj9OnTcN3A0IOUvGgKMW1rJSfAS+JNmCdPnvD2C1CkSBGCmDr9+/cfNmxYYGAgQXIDIrJgpyxbtoxojxg72yopGDBgQHJyMogLWDFbt24FeeW9JMDW1pYgpghaK7ly8eJFCGlD72rLli0bNGhA8oUYrZVsCQ8P5yUGPqEbkpcYfKyZGGCqQHglp/4L5Ndff3358uW8efO+Mv6IspINoaGhvL48evSIt1+gIvr4+BDEyBk5ciT0MdepU4cgKvz1119guQ8aNCg6OtrV1ZV8NTjiMBsqKPjxxx9TU1N5fdmxYwcYz8pADHpJRgo6QarExMQ4Oztfv349Li4OYgKQohNNIWit5J2IiAillwTOJy8xlStXJojxMGHChMYKiOhZvHjx7du3//77b6IHUFbyw/379/kRd7CgHHHn6+tLEMNmypQp4AE1b96ciJUbN244ODiULl36zJkz/NgLfYCy8lVIpVLliLuUlBTliDt7e3uCGB4zZ84MCgpq06YNESXbt2+Hjp4FCxY4OjoSfYKyojOioqJ4iYFPiO/ysd4qVaoQxGCYO3duuXLl2rdvT8QEeDrQ0Tl27Nj379+7u7sT/YMhW53h6enZTgFReEmgL+vXr797964y0Iu/cCtwRBWyTUxMhL6FJ0+eQFiQj8gKoykErRV9I5PJePsFgD485Yg7fVuhSLYsXbrUy8urW7duxNT5448/oNv4/PnzpCBAa0W/mJub11FAFL+wAIk5d+7cwoULoXLzElO1alWCCIXJWytgHcOTDFxvMI0LSlMIWisFxcOHD/lATHBwsHLEnb+/P0H0yerVq21sbPr06UNMkRMnTuzYsWP+/PkeHh6kQEFZKWDkcrky0JuQkKAMxKCXpENatGhBFA5pUlISwzD8MvSznj17lhg/+/fvByNl2rRpgkVkcwWdoAJGIpH8TwEsQ7UAfblw4cLixYshAMxLTLVq1QjydZQsWRI6VtVmHjL2Ifygj6mpqRCwu3fv3sCBA4mAEdlcQWvFQHn8+DEf6L1165ZyxF3x4sUJoj3Q8EaNGhUTE6NMKVSoEGh3QEAAMU727dsHzg7E6aytrSmKIgYGyoqhAw8l5Yi7z58/K0fcOTs7EyTPTJw48eTJk8qv9evXX7JkCTE2nj59CiYt2LbgvuV71gIBQFkxJj5+/KgMxIDFy+tL9erVCZIb0CBHjBgBbRKWIW61YMECo/Mub968CR3kYKQY/gAolBVjBbwk3oS5fv26MtCLkz9rYPbs2QcOHIAF6NRft24dMRKOHTsG4bZ58+bBQ8XNzY0YAygrRg/cQeWIOwgfKEfcaf6R+48//rhhwwYiJsLDwwcPHpyYmDhz5kyjiNfy81FPmTIFbpZx/ZAVZcWkiI6OVs7e4OLiogzEqGVr06ZNWFhYhQoVNm/erLbq8MaoyJfJMinDpDFEG1gCkUPt6hLDUjSl3IQiedo8a7bcN8zu2AxrK22yZQMtoWkzytHVotvPBjElM8qKyQLRBGWsF+IvvL6UKlUKVtWrVw8e2hAM9vHx+f3335V2zeY5bxiGlAi09wtwooh2ssK1CErLlqHYJJ38tynVUvKcIy+7y7qZ/rbKvCHNEkab7h1aInn/JvHhjbjP71IGLSxGChqUFVHAiwuoDPjnoC9HjhzheyXh7hcuXHjZsmUgN9sWvKUoSZtBXgQxWsKfyM/teTNoQQErC8qKuPj06RPoy+TJk2n6y+u3PTw8erVeFBdm22WcH0GMnCMbI8AOLVhvyBRe7Y7kHQi4rFixQlVTiGKmmJf34pw88Z3npkC56o6x0VJSoODgfdERHx9PFKPswA9ydna2s7Oz5nCwscXKYAp4+NtqG27XOViTRAfoCHg9EKwtX758yZIlixUr5ubmtm7881SpjCDGj0wml8tJwYKyIjpOnDhBEESfoKwgCKJjUFYQxMQo+B80o6wgiIlR8ENGUFYQxPQoYGVBWUE4KAOcCwjJPwV8M1FWEA4WR1ubDAbwfEBZQTjQWDEdDOD5gLKCcKCxgugQlBUEMTUK/CGBsoIgpkaBu7QoKwiC6BiUFYQHQ7aIzsD5VhAeEwnZzpw14cjRAwQpUFBWEJPi8eMHBCloUFaQfPLgQeiAgd1btv5m/MSf7t+/O3xEv+Ur5vOrPn2KnjN3ctfvW7fr0Hju/Klv377m0/ft39WhU9M3b1716de5QaOq/X7seuz4IWWBUMi48cO+bdvgh14d1qxdnpiYyKfv2buj43fNLl0+16hJ9ZWruVcR/vffxbnzpnTp1qpFqzqjxwy6E3yTzwllRkZFLF4yu03b+vA1LS3tt/W/wr5atakLB3n16qW8nNfLl89/+XVhrz6dmrWoPXBQjwMHdyvTofyHj+5PnTYWFjp3bbl23Qrl1CZXr10eNXogHE/3H9rNXzg9OvojnCZkCwm5zWc4dfoYfIUrwH/l1z54eA+W4SIMGdYbtoXP3Xu2K/txps8YN2v2RDgFyHnz1jWSNwzBm0VZQfJDSkrKpCmjnJ1d/ti4q1/fIavXLvvw4R3fAQEtbdSYgcEht0aNnPTHxp3OTi5DhvYKjwiDVebm5gkJ8b+uXPTzmKlnTt2oV7fxosWz3r2LglVh4W/HjhuSkpqyauWfs2cuefHi6ajRA0AXYJWFhUVSUuLBg7snTpjVvm1n2PXc+VNSU1MnjJ85b+4KHx+/yVNGgZBBzmNHLsPnz2OnHjpwDhZgR9BK27frsn3boXp1G02fOe78hdO5ntrqNUtv3PhvxE/jF8z/tWXLdiAxIBn8wcPn0mVzGjVqfuLYf5Mnztn1z9az57gXsD55+mjipBGVK1fb9Mfun4aPe/78ycJFM+DA3N097j+4yxd7716wh4fng4yvofeC7WztypQuB3KzcNHMUiXLbN96sH+/oXDAq9Ys5fPAHl+8fAZ/c2cvK1WqLMkbhuDNoqwgHLSEktBaPOeuXrsUG/t54IARnp6FoUn82H8Yrw5AaGgwPIonTZxdo3ptFxfXwYNGOjg67dmznV8rk8l69RxQrlwF0KBmTVvDk/nZs8eQfurUUXMzcxAUaI1+fv5jx0x9+uwxWChE0V0KUtK1a6/GjZoXKeJjZWW1cf2OMaMnVw6sCn+DBo5MTk6GVqp2hKA7x08c/r5b72/bdHR0cGzZom2jhs03b8n9jWtTp85fvHhNUOVqUHjbbzuVLlX2+o0ryrUghfXrNYYGX6lSkFdh7ydPHkLivdBgOKoe3fuCcMBZL128tlu33pBeObDaQ4U9AoTcvd28WRv4VF6lqlVr0jR95Mj+ihUrjxwxATQadtqn16D9+3fFxHziTzwqKmLm9EW1a9d1sHcgxgPKCsLByFk5o8Vz7uXLZ3Z2dv7+6e9mhRZon1HvoYVDq4MWwn+FthFYqYqyOQFlypTnF/hNwH4hnAcUAumOjk78KlArL68id0PvfNmqdHnlMhgvK1ct7tS5OXgH4DsQ7gWAMWpHCA1eKpVWq1pLmQKH8eLFs9i4WKIZlt27d0fP3h2hcPh79PjBZ0Uj51G1Guzs7PmDD6gQCMI3cfLIf3ZvA7MLzgIuCKTDReBPAST41asX37bpBM4Rr79wlYKCqjMMc+9+iOpBgskDicoT9/UpBoJFjA3sYEbyQ3xCvI2NrWqKk5MzvwAtDUwSaJDZriU5DNaCraABq20Vo3BteMAV4hegWY4Y1T+ocvWpk+fxVk+TZjWzLRA+IeKjlg5lgvFCcgCa9IRJI2QyKdhfgaCVdvZqJai9tIAH7DXwmC5cOL1+w0qIClUJqt6718CAgEpVqtSIi4sF2w0cmZIlSoPtBgd89+7t6tVrR0SEVa9WG4QPrtXvf6yBv0wHmSFkFpZG+ToElBUkP1hZWkGTUE2Jjv7AL7i6ullbW8+ds1x1rYSWaC7QxdWtQoXAPr0HqSY6OjhlzXnu/EnYNQRWYC8kOzsl/TDcCsEn+Ere3kVV093dPUnOQJTk0aP7SxavAWngU0CeCrm5k9wA3wf+4Phv3bq2Z+/fkyaP3LvnJFyKYsWKQ3jl2fMnFSpWhmwVK1SGr7REAg4UeEyQYmNj07RJq7p1G6mW5lU4/2/5ofCnhoiRAm0V2jMESuEJDF+hLyYpKYlfVbx4KQh2QOv19kpvLsxfTgAAEABJREFUGxGR4U6OzpoLLO5f8sTJfytVDFKaA+A1QCQla054/oP3xGsKkFMUtoi3j6XiUc/7I0RhAkAoB5oxyRnwVuBTqSNwDPBXzK840Uhw8K1UaSrIiptboWbNWnt6eo0cPSDqXWQR76Lg1EBnEESge/TgrJ4KAYHrN66EUDQEVtJPvHgpMP2UBwnGS2RkOMR6SX5hDaArCGMrCIfCL9GiPtasUUcikUCAA7qBIZqwZcvGQoXSmyI858HIX7JkNngr0Er3H/hn0OAfjh07qLnATp26gwMCnSAQpIAOaehV7du/C/gOWXP6+5eECMXBQ3ugcV67fuX27esQy3j/ngtYgI7AYdy8eRVkDpwm8EQgRgvBUbBuQH2gp2nFLws0H4afr7+ZmdnOXVvi4uPAeYETrFa1JgiE5q0gPjJj5rhDh/eC1EKf8d59O0BfPD0Kw6qgQJCVW5y1EhAIXwMCAl+/fgkWTVCGNfRjv2GXL587cvQAnD4cKvQojx47SM0SNDrQWkE4FEMltLCewbwfNXIiRAQ6fte0ZMky0LkDLdDMzJxfO3/uCmj2s+ZMfPAgtGhR38aNW3To0FVzgdDT8fvGnTt2/DVwcA9ozxC+hX5iiFlkzdmoYbPXr1+AXixfMR/a/PhxM3bs3Lz9703x8XGjR03q/n3fPzetg76bv7cf7tqlJ9gC23dsAumxtbUrX67imDFTNB8GOCaTJ835a/P6tu0agkU2eeLs6E8fp04b26tPJ+jlzWmrzt/1AEFZtXrJsuXzQM4aNmi2fNl6kCdYBfIBqgTdW9DRQxQvaYJ+LogcV84IaYPrt37dtm3b/wQlTUlJhoOcM3uZpXGGVJTgO5gRjnXjn3sUs27cTYv3uodHhIEzwnd8Qi1q/W29vr0Hd+zYjSAFSlyMfO8vL4cvL0EKDrRWkPwA3s2Qob1KFC/Vr99QeA7//vtqmqLr129CEIMA51tBDABtp8iGcMaCeb9s2Lhq2vSx0tTUsmUDVq/aBJ4RMXggfgHdNDmt3bplv3LsjDGD860gBoKWVRGkZNnSdcTYgFjG9u2Hclprb2dPkK8GZQXhYMU09T5qh75BWUEQUwPnskUMAois4PRwJgPOZYsYBPB4w4EGiK5AWUEQRMegrCCIScH5PwVteaKsIBz4aneTgZOUgr6XKCsIB77aHdEhKCsIgugYlBWEgzajzMzQDTIFaJbQ2MGMGAKWlmZsGk6+YwokJcol5gUsK1iTEI5CXhbRUSkEMX4e/BdjZVPA7RplBeFo2d9TmsI8uYXKYvSEPUmq2yH/c1bqBJzGCclATtZOfOFbzv6b9oUIYoQ8uhp/+9zHdoO8PXwtSIGCsoJk4o8Zr1OT5BIJkaYyGrLxMUGoO7CQtQbxiWqrqIxRWsr0bLZV/DQpp7XKnea0LeyA34v6Wn5VlqPKvExxP2DIsorbKSwzWc+OVTSfrOmU2m/9MhIo9QtCkfSpPjMuDXcMihyqO1UmKjehsjRbcwtI4V4gV6WJa1DDgn9RGcoKos7nKPI4JEaaLNOUSdnEWSqbV0hQylFZKqsycn5pXVm0QdG2iXK1+nBR1aafVVf48rOVNH4VS4VHhn+Kjq5QocKXs8jIxmbsO/MpqB2Syla0oolnSWf5gYXqusKnZDojilclSlVX6AwtUfzjZxhW6MqXC5BxvKqnLrGgPYraFq9gTQwD7AlC1HHyJDU8nYkpcuDAlejou9+0a0QQfYLWCiIioqOjk5OTixTJ/8u9kLyAsoIgiI7BDmZERJw8eXLXrl0E0TMYW0FERERERFxcHEH0DDpBiIh49+4dVHhPT0+C6BOUFQRBdAzGVhARsWfPnmPHjhFEz6CsICLizZs30MdMED2DThAiIsLDwy0tLd3cjOClrkYNygqCIDoGnSBERGzatOnSpUsE0TMoK4iIePnyZWxsLEH0DDpBiIh4/fq1g4ODs7Np/pDScEBZQRBEx6AThIiIVatWhYSEEETPoKwgIuLJkyeJiYkE0TPoBCEi4vnz5x4eHnZ2dgTRJygrCILoGHSCEBGxYMECMFgIomdwvhVERDx48CA1NZUgegadIEREPH782NfX18rKiiD6BGUFQRAdg7EVREQsW7bs/fv3BNEzKCuIiLhy5UpSUhJB9Aw6QYiIwNiKMKCsIAiiY9AJQkTE3LlzX716RRA9g+NWEBGB860IAzpBiIjA3wQJA8oKgiA6BmMriIhYvnz53bt3CaJnMLaCiIiwsLCYmBiC6Bl0ghAR8ebNG0cFBNEnKCsIgugYjK0gImLDhg1XrlwhiJ5BWUFERFRU1IcPHwiiZ9AJQkRERESElZWVi4sLQfQJygqCIDoGnSBEROzYsePEiRME0TM4bgURERBYwblsBQCdIMT0ad26NcMwsACfFEWZmZmxCv7991+C6AG0VhDTp3Dhwrdu3aLpLy4/6EutWrUIoh8wtoKYPn379nVzc1NNsbOz69atG0H0A8oKYvqAYVK+fHnVFH9//zp16hBEP6CsIKLghx9+cHZ25pdtbW27d+9OEL2BsoKIgiAF/LKPj0+TJk0IojdQVhCx0Lt3b09PTwsLiy5duhBEn2AHM5JXLh/89CwkQZoiT02Rq62iCGEzPtNTaMIymTLw/9TqG6XYTjWJ4rIRPpeyQC6R25JSy6aW+GVHLFGr1pAf/pPLGVij2iXEl6x2DOnl8Hsg6qgeoXo6q74JJCpzKpdVE1V3x2ZOUduDhTltZkm7+1i37udBDBuUFSRPHPwt8v2bFLciNi6eFlKpTHUVpWgU0Fwp7l96ooSm5YyqrmQ0OnVZoTlpUGnUXEY2XRYorrVnLHDpmQpMX1AvEApgWYZiMwsFrdAVhlGv7SAwrMoeMx0wfzpZGghN0dygF5I1neK1lVHdREVCuAyKHcECw2bZXfrZsMoTUduFuaV5Umza+1dJUhnz45xixIBBWUFyZ+u8t2lpbMcRPgQxAK4f+fzs7qeB8/2JoYKxFSQXLh+MTk5KQ00xHKq3dHJ0s/x7URgxVFBWkFx4FpLoUcSWIIZEjSaFYj9KiaGCsoLkQmqy3MndnCCGhJuvBcuwCZ+IYYKyguSCLIVh5HKCGBjQqyU31PuCPzVEEETHoKwgCKJjUFaQXKDAUZYQxBChiGGCsoLkAjcGDUMrhomhjjlDWUEQRMegrCC5QRGWwqHYiBagrCC5QHHDEAzViRc5GFtBjBTWcF14sWOwRiTKCpIbqCuGisHeFpQVBEF0DMoKkgvcRCAYWjFMMLaCGCncZEYU6opBYqheEP7UEMkN6F5mjCm4smfvjkZNqhNhKZCdGiwoK0guULRi/L7xUK5swA89+ueabd/+XfMXTic6Io87FQnoBCG5wDKZ5pA1fMqWDYC/XLM9fvyA6I487lTHGKpvitYKonuuXrs8avTAFq3qdP+hHVgE0dEf+fT//rs4d96ULt1awarRYwbdCb4JiYmJiU2a1dy67Q/l5nK5vFWbuus3rITlT5+i58yd3PX71u06NJ47f+rbt69z3buqPwJbHTi4e/OWjZDS+tt6M2dN4A9m5OgBx08cPnHi3waNqj55+ghSjh0/NGRYbzgw+Ny9Z7tyjufpM8bNmj3xt/W/Qs4//lwHn/fuhSj39fDRfUiB81XdaVpaGuTv068znMX4iT9dvXqJT+/Qqelfmzfwy7Gxn2FDOB5lUZ06Nz977iTRCoytIEYKLSGURIvHIrTSiZNGVK5cbdMfu38aPu758ycLF82A9JSUlLnzp6Smpk4YP3Pe3BU+Pn6Tp4wC1bC1ta1V85uLF88oS7h561pSUlKjhs1BX0aNGRgccmvUyEl/bNzp7OQyZGiv8Agt5nA1NzffuXMzTdP7953+6889ofeCN/31G6SvWLYejIumTVudPX2zVMkyp04fW7hoJixs33qwf7+hICur1ixVlvDi5TP4mzt7WdtvO9nb2V9QOdRLl85CSrWqNVV3+uvKRVBC+3Zdtm87VK9uo+kzx52/cBrSq1at+eBhKJ/n9p0bHh6ecDz8Vzgp0LtSpcoSkwBlBckFRq6dE3QvNNjKyqpH977QbGpUr7108dpu3XpDOiRuXL9jzOjJlQOrwt+ggSOTk5P5dlWvXmMQo8ioCL4EaKt+fv7Fi5cMDQ1+8+bVpImzoRwXF9fBg0Y6ODrt2bOdaIO3d1E4GGj8rq5u1arWevLkYdY8R47sr1ix8sgRE5ydXYIqV+vTa9D+/btiYrg5HaEXLCoqYub0RbVr14USGjRoeuHiaeWGIDGNGjWXSL7MHAG6CXbQ9916f9umo6ODY8sWbUEfN2/hjBQo+d69YN4OCgm5Vb9ek4SEeF4lQ0PvODk5e3sVISYBygqSB7R560tAhUAwTCZOHvnP7m1h4W8dHZ1ARPhVSUmJK1ctBmsf7H9wNyDl8+cY+Pxf7XqWlpa8wQKtDp7t0BRhGUQHjAVojfzm0MIDK1UJuXubaIOqCWBv75CYmKCWgWGYe/dDQHGUKWBqQeLd0Dv8V1+fYqCJ/HL9+k3evYvi/aaXL5+Hhb3hD1UJyJZUKlUtDY75xYtnsXGxVYJqgBUGW/GnViEgsEyZ8qDC3NfQ4CpBWnYksRSOW0GMFopoNWwFXIkF83+9cOE0BEfWrF0OraV3r4EBAZWgNY4Y1T+ocvWpk+eVK1cBNAJCKvwm0Ghr16p78dLZzt/1gAYWHx/XpHFLSIeHuUwmAw1SLR+e6kQbch10AyoAe/n9jzXwp5rOWyuAhaWlMhE0AiwaODs4TTjgQoXc4dRUt4Jjhs/hI/qp7SXmUzSYYEWL+oKEgdUD4gLi9fDRPdCXZs1ag4R17dKTaHdihtvrj7KC5AZLtH1FHfgs8Nen96Bbt67t2fv3pMkj9+45ee78SWjAEFixtrYmGXaKErACIDgK8QVwK8qXrwgOFCRC84PMc+csV80poXU8Vx2Imo2NTdMmrerWbaSa7lU4G5cERAr8oEuXz0EIBpw1Xv5UcXUrBJ/g64HzpZru7s6dEYgshFdAGf39S8BOK1SovHbdcgjfgtUDASaiLfhTQ8RIUUw6qYW5Ehx8K1WaCrLi5lYInsOenl7Q7RL1LjIuLhZ8EF5TAD6KqQQaFcRur167dObsceUAkOLFS0H8BRqkMugQERnu5KidtZIXYEfxCfFKZw2Ml8jIcHf37F913LB+0717d0D/ztNnjyHuo7a2iLePpcK6UZYGVg94diAisBwUVH3t2uV2tvaVKlWBr+AHQfDo1KmjEMCG4BExFTC2guQCF2LUZpQtGPkzZo47dHgv2CMPHt7bu28H6IunR2F//5JgjBw8tAf6X69dv3L79nUIu7x/H8VvBTGU2rXrHTy4Gx7d9es15hPh2V69eu0lS2aDAwXp+w/8M2jwD8eOHSS6AKyJhw/vQY8MNPsf+w27fPnckaMHIKQCXhj0KI8eOwhsq2w3BGMKFOfPTevA4gC/Rm0tyAc4fRCjhf9DZ3YAABAASURBVHKgBFDPseOGrPhlAb+2cmA1UNj//rsQUL4Sn7lkidJwiapUqUFMCJQVJFe0CwxCfKRVy/arVi9p37HJqNEDbGxsly9bb2Zm1qhhsx969IP2BiEV6M2BvmfwILb/vWnZ8nn8hvXrcv1BICUQvFCWNn/uCugnmjVnYrsOjaH5NW7cokOHrkQXtGnVATyan8cNff7iaYUKgevXbbt79w4cM6gAhHXnzF5mqRJSUQM6ceBQGzZolu1aiJL8PHba9h2b2rSt/8uvC8GZGjNmCr/Kzs6udOlyYHMp49AgUqpfTQN8tTuSC6tHPy9fy7FKUzeCGBJ/zXj6w2R/RzdDfCsCxlYQxGjBkC1irNAsRRvWAImJk0fywz2y0rJlu8GDRhKkQEFZQXLD8CZGgF7qNJks21WWllZEPOBwOMR4YQ1sGidHB0eCEHSCEGMG54ZDtAJlBckFbtJJnHrfMEEnCDFSaG1/FIQIBjpBiPGCg5sQrUBZQfIAWiuINqCsILkA/csUWiuINqCsILnBoKog2oGyguQCOEDG9UIPpMBBWUFygbNUaNQVA8RwA14oK0guWFhL5FIM2RoctBlt52iIP18mON8Kkit2jmbv3yYTxJC4/1+8uRklsSCGCcoKkgstehaJeZdCEEMi9FK0XzlbYqjgNE5I7oQ/Sz60IbJxjyIePob6fBQTe3557V3cukl3d2KooKwgeeLGsdhbZz/S5hJLK0qanEudoSSElat8pdTn7lfLoIaZGZuWllM0h5v8Re11aNBRxb0omjA0TWf7pjSKq+YqBVKK3zkpSssa+FQrR3nwWc9C8dNuKsupsaw8c5lfdpdlQyp9AD7slMrsOlA0yzKZtjKz4C5aajJTyNuq00gvYsCgrCBacHnf5/cRSalJMs3ZaDOKSftSrxRCwGrIoIbEAoLEOagOrWiPmVeml8+tgobHZrsVJwks98LWVKnU0cmB8KohoUjW/Jl3wWsWye4sst1jNqfG9aMxhMm8IUgJw34pM+MIVcqhmbRMGmluZebgbN6wjbvE4KeFQFlBRMTBgweDg4OnTZtGEH2CHcyIiEhLSzMzwzqvd/ASIyICZMXc3JwgegZlBRERaK0IA15iRESgrAgDXmJERKCsCANeYkREgKxIJAb6OxpTAgfvIyJCJpNhyFYA0FpBRAQ6QcKAlxgRESgrwoCXGBERKCvCgJcYEREYWxEGlBVERKC1Igx4iRERgbIiDHiJERGBsiIMeIkREYGyIgx4iRERgSFbYUBZQUQEWivCgJcYEREoK8KAlxgREXK5HGVFAPASIyICYisoKwKAlxgREegECQNeYkREoKwIA15iRERYWFhgB7MAoKwgIiIpKQlfjCUAKCuIiAAPCPwggugZlBVERKCsCAPKCiIiUFaEAWUFEREoK8KAsoKICJQVYUBZQUQEyoowoKwgIgJlRRhQVhARgbIiDCgriIhAWREGlBVERKCsCAPKCiIiUFaEAWUFEREoK8KAsoKICJQVYUBZQUQEyoowoKwgIgJlRRhQVhARgbIiDBTOaoOYPB07diSKGSfj4uIoirK1tWUYBmr+kSNHCKIH0FpBTB9LS8snT54ov4K4gKwEBAQQRD/QBEFMne+//97a2lo1xd7evkuXLgTRDygriOnTunXr4sWLq6Z4enq2atWKIPoBZQURBWCwODo68svgE3Xq1IkgegNlBREFTZs29ff355e9vb3btWtHEL2BsoKIhd69e4PBQtN0y5Yt8W1BegU7mJGv4sif76KjUlMTGdVEiiasSgJFsdCty0AKRQgLa1mWoWiaMIo8LGEpbgVRpkjMWHlaphSKq6eUYoGkV1iK24pf5hNhDyxLZ+wxPRu/L/544DM+LoFh5PYO9hRRz8lnhmPhvyp3rbp3tfxcHihXsVO1U+aPkHDnrTySzBlUjj9bLK0pGweLOm1cPPwsibGBsoLkk7BnyYc3RFraSOwcLaQpUtVVWWSF5lSFyWj/NMUyLC2hGDnLr2UVuWkaMnEptBnNpGVKUebht1UsKFJUWqxCspR7JBnqQMOO+QxfSlO0eLWc6YVDOkNUd622rDwAfhk+M47nS3r6WsXxqBzJF53i1xKVXWfF0sY8OVGeGCPzr2jXtIc7MSpQVpD88Oh64vk9774d4m/nRBC9smPRK6/iVq36ehLjAWMrSH44u+ddy/6+qCkC0HWcX8TT5Fsn44jxgLKCaM2xv95bWtNO7hKCCIK7r839q5+J8YCygmjNp/epNvbYkyIcXr62SYnG9AtJ/E0QojXJCXJzS4YggiGRp0mN6YKjrCAIomNQVhAE0TEoKwhi6LAUy4+RMRZQVhDE0AFVURtrZ+CgrCAIomNQVhCtoWn+RzyIQBjdQHgct4JoDfcDGfzJh4AYnYajtYIgiI5BawXRGoqw6AMhGkBrBckHFOqKkDDchDXEiEBZQbSGJUYYRTRmaJYyrvlLUFYQBNExGFtBDJEXL541aFT17t07xLBp277R5i0bCZIZlBXEEHFycu75Q3939/Qp0dp3bBIRGU4MA9WD6dL5h4oVKhMkM+gEIYaIi4trn96D+OWoqMjPn2OIYaB2MN936030Dz8BrxEhmTFjBkEQbbhz7rPEjCpbPa9TTnbo1DQlJSWwUhVYjo393KJVndevX9Sv15hf26lzc7lc/uTJo6nTxnh7F+3Tr3NcfGwhN3fYKqhyNbALBgzsDtn27t3x7Pnjhg2affoUvXTZ3DXrlm/d9sfzF0+L+RV3dMz9SK5euwxb/fLrwqPHDj55+rBc2Qo2NjaQrqG0N29eTZvx86LFs06e/PfDh/cVKwbdDb2jdjDgBMlkskqVgvj8M2dNWLl68c5dW69eu+Tp6VXY0wvS9+3fNXnKqFo1vxk5egAcwMVLZywtLUuUKE3yTHR4avizpOrNXIiRgE4QojU0TWnV31m1as0HD0P55dt3bnh4eIbeC+a/hkeERUd/hAwWFhZJSYkHD+6eOGFW+7adldtWDqw6f+4KWNi29cCcWUtBgEaNGRgccmvUyEl/bNzp7OQyZGgvKETzATx5+mjipBGVK1fb9Mfun4aPe/78ycJFMyBdQ2lglQwb3qdCQODSJWu7dOl5+syxX1cuUjsY1V3ExHyC/OC1rf9t++qVf0JRs+dMSkpKglXm5uYJCfGw+c9jpp45daNe3cYgVe/eRRHTBWUF0RqWZVlt5ioDo+PevWD+HQ8hIbfq12sCzYxvvaGhdyCMUrJEaRAqsGi6du3VuFHzIkV8cioqNDQYjIJJE2fXqF4bHKXBg0Y6ODrt2bNd8wHcCw22srLq0b0vKBpsuHTx2m4K50VDabv3bLe0sgJHDA7+2zYd+/UdovmNZf/s3mZhaTl2zBSvwt5w/D+PnZacnHTg4D/8WrBoevUcUK5cBTjNZk1bw6V49uwxMV1QVhCt4fRBG2ulSlANeG6/fPkclsFOAROgTJny0NSJomFXCaquzFmmdHnNRcHm0LyhqfNfoZWCbxVy97bmrQIqBIJmTZw8Ehp/WPhbcHPA7tBc2osXT0uWLCORpE8D3rxZmxE/jdewixcvn0F+M7P0YKWtrW3RIr5Pnjz8cmpl0k/N3t4BPkFYSZ4xupfuYMgWyRfaVPRChdyLFvW9dz/E1dUNxAWckYeP7kGTbtasNUQrunbpqcwJrpDmoqA1wpMf+p5VE8He0bxVqZJlFsz/9cKF0+s3rFyzdjkIWe9eAwMCKmkoLTExIddiVfkU/RECQ6opVtbWSclJyq/U14yTNbYxzSgrSL7QsqJDS4bwCjRUf/8SECutUKHy2nXLIXwbFvYGYpl5LweEydraeu6c5aqJEjr3V4uAmwN/4NTcunVtz96/J00euXfPSQ2l2draJSYlkjxjY2ubkpqimpKclFTE24foAvwFM2L6cM9dLWt6UFD1tWuX29naV1L0B4EfBEGNU6eO+vj4QVAj7+UUL14qOTkZIqPeXkX4FOgqcnLMxawIDr6VKk0FWXFzKwQmEvTRQKdM1LtIDaWVLl3u0OE9aWlpvF9z+szxo0cPLFywMqddlC5V7viJw2D78CGYuPi4129eNm3aiogSjK0gWsO5+lp6+5UDq0Ez/u+/CwHlK8FXMFggTLt3344qVWrkum1RHz/4PHfu5IOH98DqqV699pIls6EnBYyd/Qf+GTT4h2PHDmouAfyvGTPHHTq89/PnGCgE9gv64ulRWENprVq2k0qly5bPu3nr2sVLZzdsXOnqVghCLaoHo7qLNm06gt8EfdVQ1KtXL+YvmGZladWyRTsiStBaQYTAzs4Onv+PHt1XxkfLl6+4b/8u5VcNgCkBEdM/N60DSVq+7Dfo4j14aM+sORMfPAiFkE3jxi06dOiquYTO3/UAQVm1egnIBIRvGjZotnzZet4Myak06M2BcAwoztFjBy0tLaH7pn//YVkPRrmLIt5Fp09bsGXLxq7ft4aQcNmyAb+s2AiBWyJK8NXuiNb8Pv2VuSXVfqgvQQTh0fXY68c/Dl1SnBgJaK0gWoNz2QoNS3DmfcTEYRhWYmDzOG3/e9Pff2/KdpWvn/+qX/8giICgrCBaQymcZ2JIQMS0QYOm2a4yk2AlFxq84ojWcG/YM7AuRHs7e/gjJgoEQI3L6cQOZkRrwAnCQL+QUBRlXNcbrRUEMXQgYksZ1RzZKCsIYuhQxjYQBGUFQRAdg7KCIIiOQVlBtAaHwiGaQVlBtAZ7gRDNoKwgCKJjUFYQBNExKCuI1lhbUxJzC4IIBUMkFhbGNHIVR9kiWuPsYZ0ULyWIUES9TLS0QVlBTJoWfdxTE+UJnzB0KxDvXieVq5HXl70ZAigrSH6o28H9wNqX0mSC6JtdS157FbOq1syYZAVnh0PySdjj5MO/R1rbm9k5WqTJ0jKtozL1QlO0yvS3lOIHLpDCZMoAZH2lGSWhWDnkVnlRTuaS07/yU3arFqjYJNOGGenwJGXl6onZZOYH57Bf9qh6zOqbKPNkLkTtyPmf9XwpRFGgMg9FU6pzNZlbmSXHpcV/TvUvb9+0pzsxKlBWkK/i0PqomPfSlMRMsqLeumjFr+XSGx73K/+8ykp67i+lZdP42fQWq1agaotVwhKGIYwkc08F357VDikbqVJt9or9fklRil3mXWZ3mizLUNkepJqsWFpLbBwtajZ3KlramhgbKCuIiDh06NDt27enT59OEH2CHcyIiFC+9wfRK3iJERGhfD0YoldQVhARgdaKMOAlRkQEyoow4CVGRATKijDgJUZEBMqKMOAoW0REoKwIA15iRESgrAgDXmJERKCsCANeYkREoKwIA15iRETgcDhhQFlBRARaK8KAlxgRESgrwoCXGBERKCvCgJcYEREoK8KAlxgRERiyFQaUFUREoLUiDHiJERGBsiIMeIkREYGyIgx4iRERAbKCsRUBQFlBRARaK8KAlxgRESgrwoCXGBERKCvCgJcYERH29vYSiYS0s+awAAAIqUlEQVQgegZlBRERiYmJUqmUIHoGZQUREdANJJPJCKJnUFYQEQGBFQivEETPoKwgIgJlRRhQVhARgbIiDCgriIgAWZHL5QTRMygriIhAa0UYUFYQEYGyIgwoK4iIQFkRBpQVRESgrAgDygoiIlBWhAFlBRERKCvCgLKCiAiUFWFAWUFEBMqKMKCsICICZUUYUFYQEYGyIgwoK4iIQFkRBoplWYIgJk2bNm3Cw8OhqlMURdM0LDAM4+vru3//foLoAZogiKnTsWNHc3NziUQCmgJfQVwsLCwgkSD6AWUFMX26d+9etGhR1RQwVdq3b08Q/YCygpg+YKp06dLF0tKS/wpmS9OmTe3s7AiiH1BWEFHw3XffKQ0WHx8fNFX0CsoKIhZ69uxpa2sLgZVvvvnG1dWVIHoDe4IQQyQ6XPYsOCH6vVSWyshS5YSFOCt8gP9CGIZQNGHkhIJ8kMgSWqL4SnF//FquVkO3DywwXGmwQBhIYJ88fpImTyvhX9LC0oJSPFKVGfgFgDYjTEYfNCWhWLmigVBcgRIJJZd/aS/mlhIzc8rO2axYGVufctYEyQBlBTEg7l6MD7kYk/A5jWFAFUAvaBAOJo2ro5QiA9gasAp0RKkCikSSXoshk2IhQ4UyMhCStZZzOZiMclXTaYplWLUtOVEhlKr6EE7j4BC5wwMtgyOwsKGLB9g17FKIiB6UFcQguHroU8jlWLAFrOwsXIs4OHrZEqMi5bMs6kVMcmwyI2eKlrT7dpAnETEoK0jB8+eM1ynJjIuXg0cpJ2LkxEclRz6JTkuTN+teuHigSD0jlBWkIHn7JPnQ+gg7NxufSu7EhPjwKuHDi2i/cnYt+5jUeeURlBWkwJAmkA3TnvvXLGptb5qvW398ISyooVO1Jo5EZKCsIAXD45uJp3ZElW/kR0yah+feuhU2/26kNxETOG4FKQCkUnLq70iT1xSgbP2i0VHSMzs/EDGBsoIUAJumvXDzdSbioEw9n4fXYxNiiXhAWUGEZt+qCELTHiWNvtMn7zi42/+96CURDSgriNBEvEz2D/IiYqJoRTeZlLl69BMRBygriKDsWxPBjXm3Nc2uHw04uNuFXhKLI4SygghK1MsUVx/DdX/2HFq0eGU3ogeKBLhJU+RRr6REBKCsIMLxMjSJYVlXX3siSsyszK7++5GIAJQVRDhCr8SamYvO/VFiZWf58V0qEQE48z4iHLEfZBbW5kRv3Lh9+L8b+yLfPSvsUSKwQuNvanWlKO4Xylt2TiKECqrUfOfeWampSb5FK7RqNsy3aACsgq/bdk979uImbFKrWgeiTxzdbSMfJRERgNYKIhwpyXILG33Jyu2Q4zv3zS7iVXrS6H0tmgy+cGXHgSPL+VU0bfb6beit4KMjBm2aN+28mbnFjr2z+FW79s/9GP12YO9VvbotjHr/4tGTy0RvOHnYMgwRAygriHAwLDGz0FeVu37rgL9v5Q5txtnbuZT0r9qs0YDL1/6JT0jv0wWrpEv7Ka4u3hKJWVDFZh8+voaU2LgPIfdONajzA1guDvaurZsNMzezIvpDQliWSYg1/Z/LoKwgwqF4Pw/RB1Duyzd3S5WsoUwBZYHdvXwVzH91L+RnaWnDL1tZcTHjpOS4TzHhsODhXky5VVHvskSfUIRmpaZvsWBsBREOVg5/emlUaWlSuVx27NQ6+FNNj09Mt1YoKpsnaGISN5DE0sJGmWJhod8ZUqAjzN7F9IPWKCuIcJhbSFKT9PKuUgsLK1CHKoEtK5ZvqJoOXo+GrWxtuCkLpLIUZUpKaiLRG4mfpJy4iaArDGUFEQ57Z0lstL7Gg3kVLpWcEl/Cvwr/NS1NFh0T7uTooWETZyfuNwSv3tzlfR/Y5Onz67a2+voN5OeoeIkZRUQAxlYQ4fApbStN1deb1Vs2GXzv4flrtw5ycZbXwVt3Tf7tz6HgHGnYxMnR3c+n0vEz699/eC2TpW77Zyqh9Njskz6n2DvpsX/dcEBZQYSjVmsXiqJSE+REDxTzDRw1eDPEaGcsbP7bpuHJKQl9ui82N7fUvFW3jtN9ipRfsbbn5DkNbKwdqgd9S/Q2sZk0SVo6SBQjjHF2OERQNs16zTBm/jVENzH95/DEiEcfhiwpTkQAWiuIoNT5tlBSXDIRHx9exXgVF8tE/BiyRQSlRKCN5S769c13vlWzD6bevnt876FF2a4CJyUpOS7bVTWqtG3T/CeiIyA08/vWMdmuYhg59FVT2YVgGn7Ts2HdXtlulRSTmposazfYl4gDdIIQoZEnkzWTnlVoWizbtdAdI1Pp8VVbZWaWfchTIjGHPmaiO5KT44mWmJlZ5BTKeXjudenKDg27uhFxgNYKIjQSa1Kqsv2DM6/KNfTLuhaEIyftEBJra53FVl/deWdjayYeTSEYW0EKhGY9PZzdLZ9fjSSmzrtHMSmxKb2m+RAxgU4QUmAc3fT+9cOkMvWLEhMlLPRj0uekAfOKEZGB1gpSYLTo7W7rSD86/4aYIi+uRybGJIpQUwhaK0iBc2zLu+fB8fautj6VTeR1xe+fx0a/iXVwNes+3mQNMc2grCAFjzSZbJ3/KiVJbu1k5V2ukIW1sf4a783dD/EfEmma1GjuFtRQdK9eVoKyghgKT+8kXj74MTEujZbQZpYSCxtzCytz2lzCsl/mUmA5vx2qbPqwEUplWRWW8KmK/1MsYSk+J/ePSt+SsHwOllKkwR+TUSbXLpR5FNt8SeTzQLOhKFpCMTJWlpKWmiiTS2UyKQNdWGWqOdTvVIiIG5QVxOD473BM2NOkuBhZmhRaL5uW+kVWoIGr19gMgUhf4j/4bOmrFFqSLiLpSxRNsQy/WboEZSqZ25DXI+UOMjaliPKTNic0TZtJKFsHM3df629auVrYieIHyrmCsoIgiI7B4XAIgugYlBUEQXQMygqCIDoGZQVBEB2DsoIgiI5BWUEQRMf8HwAA///piMsDAAAABklEQVQDAGDBLh7sIVRVAAAAAElFTkSuQmCC",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Image(interview_graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "9383fcd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Analyst(name='klangat', role='Gen AI eng.', affiliation='OpenAI', description='Focus on building and deploying generative AI models.')"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "17fd570d",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [HumanMessage(\"So you said you were writing an article on langgraph?\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "5a20c557",
   "metadata": {},
   "outputs": [],
   "source": [
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "6c61caab",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "3 validation errors for InterviewState\nmax_num_turn\n  Field required [type=missing, input_value={'context': [], 'analyst'...generative AI models.')}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing\ninterview\n  Field required [type=missing, input_value={'context': [], 'analyst'...generative AI models.')}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing\nsections\n  Field required [type=missing, input_value={'context': [], 'analyst'...generative AI models.')}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValidationError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[124]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m interview = \u001b[43minterview_graph\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43manalyst\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43manalyst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_num_turn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthread\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\LLMOPs\\auto-research-report-generation\\.venv\\Lib\\site-packages\\langgraph\\pregel\\main.py:3068\u001b[39m, in \u001b[36mPregel.invoke\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, **kwargs)\u001b[39m\n\u001b[32m   3065\u001b[39m chunks: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] | Any] = []\n\u001b[32m   3066\u001b[39m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] = []\n\u001b[32m-> \u001b[39m\u001b[32m3068\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3069\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3070\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3071\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3072\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mupdates\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m   3073\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m   3074\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3075\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3076\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3077\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3078\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3079\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3080\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3081\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   3082\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m   3083\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\LLMOPs\\auto-research-report-generation\\.venv\\Lib\\site-packages\\langgraph\\pregel\\main.py:2593\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[39m\n\u001b[32m   2590\u001b[39m runtime = parent_runtime.merge(runtime)\n\u001b[32m   2591\u001b[39m config[CONF][CONFIG_KEY_RUNTIME] = runtime\n\u001b[32m-> \u001b[39m\u001b[32m2593\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mSyncPregelLoop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2594\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2595\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStreamProtocol\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_modes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2596\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2597\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2598\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2599\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcheckpointer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcheckpointer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2600\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2601\u001b[39m \u001b[43m    \u001b[49m\u001b[43mspecs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mchannels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2602\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2603\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minput_channels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2604\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream_channels_asis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2605\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2606\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2607\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmanager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2608\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdurability_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2609\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrigger_to_nodes\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrigger_to_nodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2610\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmigrate_checkpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_migrate_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2611\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2612\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcache_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2613\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2614\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# create runner\u001b[39;49;00m\n\u001b[32m   2615\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mPregelRunner\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2616\u001b[39m \u001b[43m        \u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[43mCONF\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2617\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_RUNNER_SUBMIT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mWeakMethod\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   (...)\u001b[39m\u001b[32m   2620\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnode_finished\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[43mCONF\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCONFIG_KEY_NODE_FINISHED\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2621\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2622\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# enable subgraph streaming\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\LLMOPs\\auto-research-report-generation\\.venv\\Lib\\site-packages\\langgraph\\pregel\\_loop.py:1088\u001b[39m, in \u001b[36mSyncPregelLoop.__enter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1086\u001b[39m \u001b[38;5;28mself\u001b[39m.stop = \u001b[38;5;28mself\u001b[39m.step + \u001b[38;5;28mself\u001b[39m.config[\u001b[33m\"\u001b[39m\u001b[33mrecursion_limit\u001b[39m\u001b[33m\"\u001b[39m] + \u001b[32m1\u001b[39m\n\u001b[32m   1087\u001b[39m \u001b[38;5;28mself\u001b[39m.checkpoint_previous_versions = \u001b[38;5;28mself\u001b[39m.checkpoint[\u001b[33m\"\u001b[39m\u001b[33mchannel_versions\u001b[39m\u001b[33m\"\u001b[39m].copy()\n\u001b[32m-> \u001b[39m\u001b[32m1088\u001b[39m \u001b[38;5;28mself\u001b[39m.updated_channels = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_first\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1089\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1090\u001b[39m \u001b[43m    \u001b[49m\u001b[43mupdated_channels\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mset\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mupdated_channels\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m   1091\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mupdated_channels\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1092\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1093\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1095\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\LLMOPs\\auto-research-report-generation\\.venv\\Lib\\site-packages\\langgraph\\pregel\\_loop.py:680\u001b[39m, in \u001b[36mPregelLoop._first\u001b[39m\u001b[34m(self, input_keys, updated_channels)\u001b[39m\n\u001b[32m    677\u001b[39m \u001b[38;5;66;03m# map inputs to channel updates\u001b[39;00m\n\u001b[32m    678\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m input_writes := deque(map_input(input_keys, \u001b[38;5;28mself\u001b[39m.input)):\n\u001b[32m    679\u001b[39m     \u001b[38;5;66;03m# discard any unfinished tasks from previous checkpoint\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m680\u001b[39m     discard_tasks = \u001b[43mprepare_next_tasks\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    681\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    682\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcheckpoint_pending_writes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    683\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    684\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mchannels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    685\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmanaged\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    686\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    687\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    688\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    689\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfor_execution\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    690\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    691\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcheckpointer\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    692\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmanager\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    693\u001b[39m \u001b[43m        \u001b[49m\u001b[43mupdated_channels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mupdated_channels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    694\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    695\u001b[39m     \u001b[38;5;66;03m# apply input writes\u001b[39;00m\n\u001b[32m    696\u001b[39m     updated_channels = apply_writes(\n\u001b[32m    697\u001b[39m         \u001b[38;5;28mself\u001b[39m.checkpoint,\n\u001b[32m    698\u001b[39m         \u001b[38;5;28mself\u001b[39m.channels,\n\u001b[32m   (...)\u001b[39m\u001b[32m    704\u001b[39m         \u001b[38;5;28mself\u001b[39m.trigger_to_nodes,\n\u001b[32m    705\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\LLMOPs\\auto-research-report-generation\\.venv\\Lib\\site-packages\\langgraph\\pregel\\_algo.py:467\u001b[39m, in \u001b[36mprepare_next_tasks\u001b[39m\u001b[34m(checkpoint, pending_writes, processes, channels, managed, config, step, stop, for_execution, store, checkpointer, manager, trigger_to_nodes, updated_channels, retry_policy, cache_policy)\u001b[39m\n\u001b[32m    464\u001b[39m \u001b[38;5;66;03m# Check if any processes should be run in next step\u001b[39;00m\n\u001b[32m    465\u001b[39m \u001b[38;5;66;03m# If so, prepare the values to be passed to them\u001b[39;00m\n\u001b[32m    466\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m candidate_nodes:\n\u001b[32m--> \u001b[39m\u001b[32m467\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m task := \u001b[43mprepare_single_task\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    468\u001b[39m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[43mPULL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    469\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    470\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    471\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcheckpoint_id_bytes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcheckpoint_id_bytes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    472\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcheckpoint_null_version\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnull_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    473\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpending_writes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpending_writes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    474\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprocesses\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprocesses\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    475\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchannels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchannels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    476\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmanaged\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmanaged\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    477\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    478\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    479\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    480\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfor_execution\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfor_execution\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    481\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    482\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcheckpointer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcheckpointer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    483\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmanager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmanager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    484\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    485\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    486\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    487\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    488\u001b[39m         tasks.append(task)\n\u001b[32m    489\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m {t.id: t \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m tasks}\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\LLMOPs\\auto-research-report-generation\\.venv\\Lib\\site-packages\\langgraph\\pregel\\_algo.py:807\u001b[39m, in \u001b[36mprepare_single_task\u001b[39m\u001b[34m(task_path, task_id_checksum, checkpoint, checkpoint_id_bytes, checkpoint_null_version, pending_writes, processes, channels, managed, config, step, stop, for_execution, store, checkpointer, manager, input_cache, cache_policy, retry_policy)\u001b[39m\n\u001b[32m    805\u001b[39m \u001b[38;5;66;03m# create task input\u001b[39;00m\n\u001b[32m    806\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m807\u001b[39m     val = \u001b[43m_proc_input\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    808\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    809\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmanaged\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    810\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchannels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    811\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfor_execution\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfor_execution\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    812\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    813\u001b[39m \u001b[43m        \u001b[49m\u001b[43mscratchpad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mscratchpad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    814\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    815\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m val \u001b[38;5;129;01mis\u001b[39;00m MISSING:\n\u001b[32m    816\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\LLMOPs\\auto-research-report-generation\\.venv\\Lib\\site-packages\\langgraph\\pregel\\_algo.py:1057\u001b[39m, in \u001b[36m_proc_input\u001b[39m\u001b[34m(proc, managed, channels, for_execution, scratchpad, input_cache)\u001b[39m\n\u001b[32m   1055\u001b[39m \u001b[38;5;66;03m# If the process has a mapper, apply it to the value\u001b[39;00m\n\u001b[32m   1056\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m for_execution \u001b[38;5;129;01mand\u001b[39;00m proc.mapper \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1057\u001b[39m     val = \u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1059\u001b[39m \u001b[38;5;66;03m# Cache the input value\u001b[39;00m\n\u001b[32m   1060\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m input_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\LLMOPs\\auto-research-report-generation\\.venv\\Lib\\site-packages\\langgraph\\graph\\state.py:1239\u001b[39m, in \u001b[36m_coerce_state\u001b[39m\u001b[34m(schema, input)\u001b[39m\n\u001b[32m   1238\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_coerce_state\u001b[39m(schema: \u001b[38;5;28mtype\u001b[39m[Any], \u001b[38;5;28minput\u001b[39m: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]) -> \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[32m-> \u001b[39m\u001b[32m1239\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mschema\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\LLMOPs\\auto-research-report-generation\\.venv\\Lib\\site-packages\\pydantic\\main.py:253\u001b[39m, in \u001b[36mBaseModel.__init__\u001b[39m\u001b[34m(self, **data)\u001b[39m\n\u001b[32m    251\u001b[39m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[32m    252\u001b[39m __tracebackhide__ = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m253\u001b[39m validated_self = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m validated_self:\n\u001b[32m    255\u001b[39m     warnings.warn(\n\u001b[32m    256\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mA custom validator is returning a value other than `self`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m    257\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mReturning anything other than `self` from a top level model validator isn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt supported when validating via `__init__`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    258\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mSee the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    259\u001b[39m         stacklevel=\u001b[32m2\u001b[39m,\n\u001b[32m    260\u001b[39m     )\n",
      "\u001b[31mValidationError\u001b[39m: 3 validation errors for InterviewState\nmax_num_turn\n  Field required [type=missing, input_value={'context': [], 'analyst'...generative AI models.')}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing\ninterview\n  Field required [type=missing, input_value={'context': [], 'analyst'...generative AI models.')}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing\nsections\n  Field required [type=missing, input_value={'context': [], 'analyst'...generative AI models.')}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing",
      "Before task with name 'ask_question' and path '('__pregel_pull', 'ask_question')'"
     ]
    }
   ],
   "source": [
    "interview = interview_graph.invoke({\"analyst\": analyst, \"messages\": messages, \"max_num_turn\": 2}, thread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ebfa31c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = {\"max_num_turns\":2, \"context\":[], \"analyst\":analyst, \"interview\":\"\",\"section\":[],\"messages\":[HumanMessage(content=\"Hi do proper search according to the expertise\")]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b99a81a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_num_turns': 2,\n",
       " 'context': [],\n",
       " 'analyst': Analyst(name='klangat', role='Gen AI eng.', affiliation='OpenAI', description='Focus on building and deploying generative AI models.'),\n",
       " 'interview': '',\n",
       " 'section': [],\n",
       " 'messages': [HumanMessage(content='Hi do proper search according to the expertise', additional_kwargs={}, response_metadata={})]}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "07c895c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': [AIMessage(content=\"Hello, my name is Rachel Kim, and I'm an analyst focusing on emerging technologies. I'm excited to be speaking with Klangat, a Gen AI engineer at OpenAI, to learn more about building and deploying generative AI models.\\n\\nKlangat, thanks for taking the time to chat with me today. I'd love to dive right in and explore some of the interesting work you're doing. Can you tell me about a particularly challenging project you've worked on recently, and how you overcame any obstacles that came up during the development and deployment of a generative AI model?\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 120, 'prompt_tokens': 221, 'total_tokens': 341, 'completion_time': 0.364142907, 'prompt_time': 0.020140994, 'queue_time': 0.085852071, 'total_time': 0.384283901}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_34d416ee39', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--e438d749-5c27-44b7-9436-467bb6958c15-0', usage_metadata={'input_tokens': 221, 'output_tokens': 120, 'total_tokens': 341})]}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_question(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "45c77931",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "result = generate_question(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "962c54b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My name is Rachel Kim, and I'm an analyst focusing on emerging technologies. I'm excited to learn from Klangat, a Gen AI engineer at OpenAI, about the latest developments in building and deploying generative AI models.\n",
      "\n",
      "Klangat, thanks for taking the time to speak with me today. I'd love to dive right in and explore some of the most interesting and specific aspects of your work. Can you tell me about a particularly innovative project you've worked on recently, perhaps one that showcases a unique application of generative AI? What made it stand out, and what were some of the key challenges you faced during its development?\n"
     ]
    }
   ],
   "source": [
    "print(result[\"messages\"][0].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "feb7fb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = {\"max_num_turns\":2,\"context\":[],\"analyst\":analyst,\"interview\":\"\",\"section\":[],'messages': [AIMessage(content=\"Hello, my name is Alex Thompson, and I'm an analyst interested in understanding the strategic implications of adopting Langgraph for businesses. I'm particularly keen on how this framework can drive innovation and support digital transformation initiatives. Thank you for taking the time to speak with me today, Michael. \\n\\nTo start, could you explain what Langgraph is and why it's becoming a significant consideration for businesses looking to innovate?\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 79, 'prompt_tokens': 224, 'total_tokens': 303, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_cbf1785567', 'id': 'chatcmpl-CPRmMT7ufhFyYLhMtNpeguI9W2y6O', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--827b799b-ccb9-422c-a444-402d7ddc4550-0', usage_metadata={'input_tokens': 224, 'output_tokens': 79, 'total_tokens': 303, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e575f6ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "result = search_web(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b12aadd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<Document href=\"https://www.merriam-webster.com/dictionary/message\"/>\\n: a communication in writing, in speech, or by signals\\n\\n2\\n\\n: a messenger\\'s errand or function\\n\\n3\\n\\n: an underlying theme or idea\\n\\nEtymology\\n\\nNoun\\n\\nMiddle English message \"job or function of a messenger,\" from early French message (same meaning), from Latin missaticum \"something given to a messenger to deliver,\" from earlier missus (past participle of mittere \"to send, throw\") and -aticum \"action, result\"  related to emit, mission, promise, submissive\\n\\n## More from Merriam-Webster on message [...] Est. 1828\\n\\nDictionary Definition\\n\\n noun\\n verb\\n noun 2 \\n  + noun\\n  + verb\\n Synonyms\\n Example Sentences\\n Word History\\n Phrases Containing\\n Rhymes\\n Entries Near\\n\\n + Cite this EntryCitation\\n  + Share\\n  + Kids DefinitionKids\\n  + More from M-W\\n\\n   Show more\\n Show more \\n  + Citation\\n  + Share\\n  + Kids\\n  + More from M-W\\n\\n + To save this word, you\\'ll need to log in.\\n\\n    Log In\\n\\n# message\\n\\n1 of 2\\n\\n## noun\\n\\nmes\\u200bsage  me-sij\")\\n\\nSynonyms of message\\n\\n: a communication in writing, in speech, or by signals [...] message\\n</Document>\\n\\n---\\n\\n<Document href=\"https://www.dictionary.com/browse/message\"/>\\n## verb (used with object)\\n\\n1. to send (a person) a message.\\n2. to send as a message.\\n\\nmessage\\n\\n/ msd/\\n\\n## noun\\n\\n1. a communication, usually brief, from one person or group to another\\n2. an implicit meaning or moral, as in a work of art\\n3. a formal communiqu\\n4. an inspired communication of a prophet or religious leader\\n5. a mission; errand\\n6. (plural) shopping\\n\\n   going for the messages\\n7. informal,  to understand what is meant\\n\\n## verb [...] 1. a communication containing some information, news, advice, request, or the like, sent by messenger, telephone, email, or other means.\\n2. an official communication, as from a chief executive to a legislative body. [...] the president\\'s message to Congress.\\n3. Digital Technology.,  a post or reply on an online message board.\\n4. the inspired utterance of a prophet or sage.\\n5. the point, moral, or meaning of a gesture, utterance, novel, motion picture, etc.\\n6. Computers.,  a warning, permission, etc., communicated by the system or software to the user.\\n\\n   an error message;\\n\\n   a message to allow blocked content.\\n\\n## verb (used without object)\\n\\n1. to send a message, especially an electronic message.\\n</Document>\\n\\n---\\n\\n<Document href=\"https://av1611.com/kjbp/kjv-dictionary/message.html\"/>\\n1. KJV Dictionary\\n2. M\\n3. message\\n\\n  mess\\n messenger \\n\\n# KJV Dictionary Definition: message\\n\\n## message\\n\\nMES\\'SAGE, n. L. missus, mitto, to send.\\n\\n1. Any notice, word or communication, written or verbal, sent from one person to another. We send a servant with a verbal or written message.\\n\\nThe welcome message made, was soon received. [...] 2. An official written communication of facts or opinions sent by a chief magistrate to the two houses of a legislature or other deliberative body. Congress receives a message from the President of the United States at the opening of the session. The Governors of some of the states communicate to the legislature by message, others by address.\\n\\n3. An official verbal communication from one branch of a legislature to the other.\\n</Document>\\n\\n---\\n\\n<Document href=\"https://www.collinsdictionary.com/us/dictionary/english/message\"/>\\nWord forms: 3rd person singular present tense messages,  present participle messaging,  past tense, past participle messaged\\n\\n1. countable noun\\n\\nA message is a piece of information or a request that you send to someone or leave for them when you cannot speak to them directly.\\n\\nI got a message you were trying to reach me.\\n\\nSynonyms:  communication, note, bulletin, word   More Synonyms of message\\n\\n2. countable noun [...] Word origin\\n\\nOFr < ML missaticum < pp. of L mittere, to send: see  mission\\n\\nCOBUILD frequency band\\n\\n## message in American English\\n\\n(mesd)\\n\\nnoun\\n\\n1. \\n\\na communication containing some information, news, advice, request, or the like, sent by messenger, radio, telephone, or other means\\n\\n2. \\n\\nan official communication, as from a chief executive to a legislative body\\n\\nthe President\\'s message to Congress\\n\\n3. \\n\\nthe inspired utterance of a prophet or sage\\n\\n4. Computing [...] American English: message \\n  /msd/\\n Arabic: \\n Brazilian Portuguese: mensagem\\n Chinese: \\n Croatian: poruka\\n Czech: vzkaz\\n Danish: besked\\n Dutch: bericht\\n European Spanish: mensaje\\n Finnish: viesti\\n French: message\\n German: Botschaft \\n  Mitteilung\\n Greek: \\n Italian: messaggio\\n Japanese: \\n Korean: \\n Norwegian: melding\\n Polish: wiadomo\\n European Portuguese: mensagem\\n Romanian: mesaj\\n Russian: \\n Spanish: mensaje\\n Swedish: meddelande\\n Thai: \\n</Document>\\n\\n---\\n\\n<Document href=\"https://en.wikipedia.org/wiki/Message\"/>\\nNot to be confused with Massage or Messuage.\\n\\nA message is a unit of communication that conveys information from a sender to a receiver. It can be transmitted through various forms, such as spoken or written words, signals, or electronic data, and can range from simple instructions to complex information. [...] In communication between humans, messages can be verbal or nonverbal:\\n\\n A verbal message is an exchange of information using words. Examples include face-to-face communication, telephone calls, voicemails, emails, etc.\\n A nonverbal message is communicated through actions or behaviors rather than words, such as conscious or unconscious body language. [...] In contrast, messages serve a broader role, encompassing commands (e.g., ProcessPayment), events (e.g., PaymentProcessed), and documents (e.g., DataPayload). Both events and messages can support various delivery guarantees, including at-least-once, at-most-once, and exactly-once, depending on the technology stack and implementation. However, exactly-once delivery is often achieved through idempotency mechanisms rather than true, infrastructure-level exactly-once semantics.\\n</Document>'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"context\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "830c5c54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Document href=\"https://www.merriam-webster.com/dictionary/message\"/>\n",
      ": a communication in writing, in speech, or by signals\n",
      "\n",
      "2\n",
      "\n",
      ": a messenger's errand or function\n",
      "\n",
      "3\n",
      "\n",
      ": an underlying theme or idea\n",
      "\n",
      "Etymology\n",
      "\n",
      "Noun\n",
      "\n",
      "Middle English message \"job or function of a messenger,\" from early French message (same meaning), from Latin missaticum \"something given to a messenger to deliver,\" from earlier missus (past participle of mittere \"to send, throw\") and -aticum \"action, result\"  related to emit, mission, promise, submissive\n",
      "\n",
      "## More from Merriam-Webster on message [...] Est. 1828\n",
      "\n",
      "Dictionary Definition\n",
      "\n",
      " noun\n",
      " verb\n",
      " noun 2 \n",
      "  + noun\n",
      "  + verb\n",
      " Synonyms\n",
      " Example Sentences\n",
      " Word History\n",
      " Phrases Containing\n",
      " Rhymes\n",
      " Entries Near\n",
      "\n",
      " + Cite this EntryCitation\n",
      "  + Share\n",
      "  + Kids DefinitionKids\n",
      "  + More from M-W\n",
      "\n",
      "   Show more\n",
      " Show more \n",
      "  + Citation\n",
      "  + Share\n",
      "  + Kids\n",
      "  + More from M-W\n",
      "\n",
      " + To save this word, you'll need to log in.\n",
      "\n",
      "    Log In\n",
      "\n",
      "# message\n",
      "\n",
      "1 of 2\n",
      "\n",
      "## noun\n",
      "\n",
      "message  me-sij\")\n",
      "\n",
      "Synonyms of message\n",
      "\n",
      ": a communication in writing, in speech, or by signals [...] message\n",
      "</Document>\n",
      "\n",
      "---\n",
      "\n",
      "<Document href=\"https://www.dictionary.com/browse/message\"/>\n",
      "## verb (used with object)\n",
      "\n",
      "1. to send (a person) a message.\n",
      "2. to send as a message.\n",
      "\n",
      "message\n",
      "\n",
      "/ msd/\n",
      "\n",
      "## noun\n",
      "\n",
      "1. a communication, usually brief, from one person or group to another\n",
      "2. an implicit meaning or moral, as in a work of art\n",
      "3. a formal communiqu\n",
      "4. an inspired communication of a prophet or religious leader\n",
      "5. a mission; errand\n",
      "6. (plural) shopping\n",
      "\n",
      "   going for the messages\n",
      "7. informal,  to understand what is meant\n",
      "\n",
      "## verb [...] 1. a communication containing some information, news, advice, request, or the like, sent by messenger, telephone, email, or other means.\n",
      "2. an official communication, as from a chief executive to a legislative body. [...] the president's message to Congress.\n",
      "3. Digital Technology.,  a post or reply on an online message board.\n",
      "4. the inspired utterance of a prophet or sage.\n",
      "5. the point, moral, or meaning of a gesture, utterance, novel, motion picture, etc.\n",
      "6. Computers.,  a warning, permission, etc., communicated by the system or software to the user.\n",
      "\n",
      "   an error message;\n",
      "\n",
      "   a message to allow blocked content.\n",
      "\n",
      "## verb (used without object)\n",
      "\n",
      "1. to send a message, especially an electronic message.\n",
      "</Document>\n",
      "\n",
      "---\n",
      "\n",
      "<Document href=\"https://av1611.com/kjbp/kjv-dictionary/message.html\"/>\n",
      "1. KJV Dictionary\n",
      "2. M\n",
      "3. message\n",
      "\n",
      "  mess\n",
      " messenger \n",
      "\n",
      "# KJV Dictionary Definition: message\n",
      "\n",
      "## message\n",
      "\n",
      "MES'SAGE, n. L. missus, mitto, to send.\n",
      "\n",
      "1. Any notice, word or communication, written or verbal, sent from one person to another. We send a servant with a verbal or written message.\n",
      "\n",
      "The welcome message made, was soon received. [...] 2. An official written communication of facts or opinions sent by a chief magistrate to the two houses of a legislature or other deliberative body. Congress receives a message from the President of the United States at the opening of the session. The Governors of some of the states communicate to the legislature by message, others by address.\n",
      "\n",
      "3. An official verbal communication from one branch of a legislature to the other.\n",
      "</Document>\n",
      "\n",
      "---\n",
      "\n",
      "<Document href=\"https://www.collinsdictionary.com/us/dictionary/english/message\"/>\n",
      "Word forms: 3rd person singular present tense messages,  present participle messaging,  past tense, past participle messaged\n",
      "\n",
      "1. countable noun\n",
      "\n",
      "A message is a piece of information or a request that you send to someone or leave for them when you cannot speak to them directly.\n",
      "\n",
      "I got a message you were trying to reach me.\n",
      "\n",
      "Synonyms:  communication, note, bulletin, word   More Synonyms of message\n",
      "\n",
      "2. countable noun [...] Word origin\n",
      "\n",
      "OFr < ML missaticum < pp. of L mittere, to send: see  mission\n",
      "\n",
      "COBUILD frequency band\n",
      "\n",
      "## message in American English\n",
      "\n",
      "(mesd)\n",
      "\n",
      "noun\n",
      "\n",
      "1. \n",
      "\n",
      "a communication containing some information, news, advice, request, or the like, sent by messenger, radio, telephone, or other means\n",
      "\n",
      "2. \n",
      "\n",
      "an official communication, as from a chief executive to a legislative body\n",
      "\n",
      "the President's message to Congress\n",
      "\n",
      "3. \n",
      "\n",
      "the inspired utterance of a prophet or sage\n",
      "\n",
      "4. Computing [...] American English: message \n",
      "  /msd/\n",
      " Arabic: \n",
      " Brazilian Portuguese: mensagem\n",
      " Chinese: \n",
      " Croatian: poruka\n",
      " Czech: vzkaz\n",
      " Danish: besked\n",
      " Dutch: bericht\n",
      " European Spanish: mensaje\n",
      " Finnish: viesti\n",
      " French: message\n",
      " German: Botschaft \n",
      "  Mitteilung\n",
      " Greek: \n",
      " Italian: messaggio\n",
      " Japanese: \n",
      " Korean: \n",
      " Norwegian: melding\n",
      " Polish: wiadomo\n",
      " European Portuguese: mensagem\n",
      " Romanian: mesaj\n",
      " Russian: \n",
      " Spanish: mensaje\n",
      " Swedish: meddelande\n",
      " Thai: \n",
      "</Document>\n",
      "\n",
      "---\n",
      "\n",
      "<Document href=\"https://en.wikipedia.org/wiki/Message\"/>\n",
      "Not to be confused with Massage or Messuage.\n",
      "\n",
      "A message is a unit of communication that conveys information from a sender to a receiver. It can be transmitted through various forms, such as spoken or written words, signals, or electronic data, and can range from simple instructions to complex information. [...] In communication between humans, messages can be verbal or nonverbal:\n",
      "\n",
      " A verbal message is an exchange of information using words. Examples include face-to-face communication, telephone calls, voicemails, emails, etc.\n",
      " A nonverbal message is communicated through actions or behaviors rather than words, such as conscious or unconscious body language. [...] In contrast, messages serve a broader role, encompassing commands (e.g., ProcessPayment), events (e.g., PaymentProcessed), and documents (e.g., DataPayload). Both events and messages can support various delivery guarantees, including at-least-once, at-most-once, and exactly-once, depending on the technology stack and implementation. However, exactly-once delivery is often achieved through idempotency mechanisms rather than true, infrastructure-level exactly-once semantics.\n",
      "</Document>\n"
     ]
    }
   ],
   "source": [
    "print(result[\"context\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2b36c938",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = {\"max_num_turns\":2,\"context\":[],\"analyst\":analyst,\"interview\":\"\",\"section\":[],'messages': [AIMessage(content=\"Hello, my name is Alex Thompson, and I'm an analyst interested in understanding the strategic implications of adopting Langgraph for businesses. I'm particularly keen on how this framework can drive innovation and support digital transformation initiatives. Thank you for taking the time to speak with me today, Michael. \\n\\nTo start, could you explain what Langgraph is and why it's becoming a significant consideration for businesses looking to innovate?\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 79, 'prompt_tokens': 224, 'total_tokens': 303, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_cbf1785567', 'id': 'chatcmpl-CPRmMT7ufhFyYLhMtNpeguI9W2y6O', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--827b799b-ccb9-422c-a444-402d7ddc4550-0', usage_metadata={'input_tokens': 224, 'output_tokens': 79, 'total_tokens': 303, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "339ea5f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "search_query='What is Langgraph and its significance for business innovation'\n"
     ]
    }
   ],
   "source": [
    "result = search_wikipedia(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a7eb8242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['']\n"
     ]
    }
   ],
   "source": [
    "print(result[\"context\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8b692f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_docs = WikipediaLoader(query=\"Langgraph\").load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "47943746",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'title': 'LangChain', 'summary': \"LangChain is a software framework that helps facilitate the integration of large language models (LLMs) into applications. As a language model integration framework, LangChain's use-cases largely overlap with those of language models in general, including document analysis and summarization, chatbots, and code analysis.\\n\\n\", 'source': 'https://en.wikipedia.org/wiki/LangChain'}, page_content='LangChain is a software framework that helps facilitate the integration of large language models (LLMs) into applications. As a language model integration framework, LangChain\\'s use-cases largely overlap with those of language models in general, including document analysis and summarization, chatbots, and code analysis.\\n\\n\\n== History ==\\nLangChain was launched in October 2022 as an open source project by Harrison Chase, while working at machine learning startup Robust Intelligence. In April 2023, LangChain had incorporated and the new startup raised over $20 million in funding at a valuation of at least $200 million from venture firm Sequoia Capital, a week after announcing a $10 million seed investment from Benchmark.\\nIn the third quarter of 2023, the LangChain Expression Language (LCEL) was introduced, which provides a declarative way to define chains of actions.\\nIn October 2023 LangChain introduced LangServe, a deployment tool to host LCEL code as a production-ready API.\\nIn February 2024 LangChain released LangSmith, a closed-source observability and evaluation platform for LLM applications, and announced a US $25 million Series A led by Sequoia Capital. On 14 May 2025 the company launched LangGraph Platform into general availability, providing managed infrastructure for deploying long-running, stateful AI agents.\\n\\n\\n== Capabilities ==\\nLangChain\\'s developers highlight the framework\\'s applicability to use-cases including chatbots, retrieval-augmented generation,  document summarization, and synthetic data generation.\\nAs of March 2023, LangChain included integrations with systems including Amazon, Google, and Microsoft Azure cloud storage; API wrappers for news, movie information, and weather; Bash for summarization, syntax and semantics checking, and execution of shell scripts; multiple web scraping subsystems and templates; few-shot learning prompt generation support; finding and summarizing \"todo\" tasks in code; Google Drive documents, spreadsheets, and presentations summarization, extraction, and creation; Google Search and Microsoft Bing web search; OpenAI, Anthropic, and Hugging Face language models; iFixit repair guides and wikis search and summarization; MapReduce for question answering, combining documents, and question generation; N-gram overlap scoring; PyPDF, pdfminer, fitz, and pymupdf for PDF file text extraction and manipulation; Python and JavaScript code generation, analysis, and debugging; Milvus vector database to store and retrieve vector embeddings; Weaviate vector database to cache embedding and data objects; Redis cache database storage; Python RequestsWrapper and other methods for API requests; SQL and NoSQL databases including JSON support; Streamlit, including for logging; text mapping for k-nearest neighbors search; time zone conversion and calendar operations; tracing and recording stack symbols in threaded and asynchronous subprocess runs; and the Wolfram Alpha website and SDK. As of April 2023, it can read from more than 50 document types and data sources.\\n\\n\\n== LangChain tools ==\\n\\n\\n== References ==\\n\\n\\n== External links ==\\n\\nOfficial website\\nDiscord server support hub\\nLangchain-ai on GitHub')]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d9f570",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
